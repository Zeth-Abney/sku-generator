{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb73f2f1",
   "metadata": {},
   "source": [
    "# Sku Generator Beta Testing Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4993eae4",
   "metadata": {},
   "source": [
    "Read Apple Numbers file with multiple sheets into Pandas Data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ee285f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numbers_parser import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "24a4466e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Product_Catalog:\n",
      "   Index Main Category           Sub Category                       Name  \\\n",
      "0    0.0         Shirt              Tee Shirt         Bandit Banquet Tee   \n",
      "1    1.0         Shirt              Tee Shirt    Bandit Truck Wreath Tee   \n",
      "2    2.0         Shirt              Tee Shirt      Bandit Truck Logo Tee   \n",
      "3    3.0         Shirt              Tee Shirt              Legendary Tee   \n",
      "4    4.0         Shirt  Long Sleeve Tee Shirt  Legendary Long Sleeve Tee   \n",
      "\n",
      "                       Size     Fit                     Color  \\\n",
      "0  S,M,L,XL,2XL,3XL,4XL,5XL  Unisex                    Yellow   \n",
      "1  S,M,L,XL,2XL,3XL,4XL,5XL  Unisex                     Black   \n",
      "2  S,M,L,XL,2XL,3XL,4XL,5XL  Unisex                     Black   \n",
      "3  S,M,L,XL,2XL,3XL,4XL,5XL  Unisex  White, Blue, Gray, Black   \n",
      "4  S,M,L,XL,2XL,3XL,4XL,5XL  Unisex                      Blue   \n",
      "\n",
      "                                    Design Material           Scent  \n",
      "0                           Bandit Banquet   Cotton  Not Applicable  \n",
      "1                        Bandit Truck Icon   Cotton  Not Applicable  \n",
      "2  Bandit Truck Icon;Bandit Truck Wordmark   Cotton  Not Applicable  \n",
      "3        Legendary Icon;Legendary Wordmark   Cotton  Not Applicable  \n",
      "4        Legendary Icon;Legendary Wordmark    Nylon  Not Applicable  \n",
      "\n",
      "Prefix_Codes:\n",
      "  Prefix         Feature     Comments\n",
      "0    NAN  Not Applicable         None\n",
      "1     MA   Main Category      Apparel\n",
      "2     MB   Main Category  Accessories\n",
      "3     MP   Main Category        Parts\n",
      "4     US    Sub Category       Shirts\n",
      "\n",
      "Main_Category:\n",
      "   Code Prefix            Name Comments\n",
      "0   0.0   MNAN  Not Applicable     None\n",
      "1   1.0     MA           Shirt     None\n",
      "2   2.0     MA       Outerwear     None\n",
      "3   3.0     MA        Headwear     None\n",
      "4   4.0     MB     Accessories     None\n",
      "\n",
      "Sub_Category:\n",
      "    Code Prefix                   Name Main Category Comments\n",
      "0    0.0   UNAN         Not Applicable          None     None\n",
      "1  101.0     US              Tee Shirt         Shirt     None\n",
      "2  102.0     US  Long Sleeve Tee Shirt         Shirt     None\n",
      "3  103.0     US                   Polo         Shirt     None\n",
      "4  201.0     UO                Sweater     Outerwear     None\n",
      "\n",
      "Size:\n",
      "   Code Prefix Abbreviation            Name           Comments\n",
      "0   0.0   SNAN           NA  Not Applicable  Non Apparel Items\n",
      "1   1.0     SZ           CS     Child Small               None\n",
      "2   2.0     SZ           CM    Child Medium               None\n",
      "3   3.0     SZ           CL     Child Large               None\n",
      "4   4.0     SZ           XS     Extra Small               None\n",
      "\n",
      "Fit:\n",
      "   Code Prefix            Name Comments\n",
      "0   0.0  FTNAN  Not Applicable     None\n",
      "1   1.0     FT          Unisex     None\n",
      "2   2.0     FT            Male     None\n",
      "3   3.0     FT          Female     None\n",
      "\n",
      "Color:\n",
      "   Code Prefix    Name Comments\n",
      "0   0.0  CLNAN      NA     None\n",
      "1   1.0     CL   White     None\n",
      "2   2.0     CL   Black     None\n",
      "3   3.0     CL    Gray     None\n",
      "4   4.0     CL  Yellow     None\n",
      "\n",
      "Design:\n",
      "   Code Prefix                Name Comments\n",
      "0   0.0   DNAN      Not Applicable     None\n",
      "1   1.0      D      Bandit Banquet     None\n",
      "2   2.0      D      Legendary Icon     None\n",
      "3   3.0      D  Legendary Wordmark     None\n",
      "4   4.0      D   Bandit Truck Icon     None\n",
      "\n",
      "Material:\n",
      "   Code  Prefix            Name Comments\n",
      "0   0.0  MATNAN  Not Applicable     None\n",
      "1   1.0     MAT          Cotton     None\n",
      "2   2.0     MAT           Nylon     None\n",
      "3   3.0     MAT           Blend     None\n",
      "4   4.0     MAT         Leather     None\n",
      "\n",
      "Scent:\n",
      "   Code Prefix              Name Comments\n",
      "0   0.0  STNAN    Not Applicable     None\n",
      "1   1.0     ST  Callahan Leather     None\n",
      "2   2.0     ST   Vanilla Leather     None\n",
      "3   3.0     ST    Cowboy Cologne     None\n"
     ]
    }
   ],
   "source": [
    "# Read the Numbers file\n",
    "doc = Document(\"CHARTS/catalog.numbers\")\n",
    "sheets = doc.sheets\n",
    "tables = {}\n",
    "\n",
    "# Extract each sheet as a separate dataframe\n",
    "for sheet in sheets:\n",
    "    for table in sheet.tables:\n",
    "        table_name = table.name.replace(\" \", \"_\")\n",
    "        data = table.rows(values_only=True)\n",
    "        tables[table_name] = pd.DataFrame(data[1:], columns=data[0])\n",
    "\n",
    "# Access individual dataframes\n",
    "for name, df in tables.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(df.head())\n",
    "\n",
    "#For Product Catalog sheet replace spaces with underscores in column names\n",
    "tables['Product_Catalog'].columns = tables['Product_Catalog'].columns.str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e357ae0d",
   "metadata": {},
   "source": [
    "# Prepare Data for parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c526a54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet names and catalog features MATCH exactly!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sheet_Names</th>\n",
       "      <th>Catalog_Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Main_Category</td>\n",
       "      <td>Main_Category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sub_Category</td>\n",
       "      <td>Sub_Category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Size</td>\n",
       "      <td>Size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fit</td>\n",
       "      <td>Fit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Color</td>\n",
       "      <td>Color</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Design</td>\n",
       "      <td>Design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Material</td>\n",
       "      <td>Material</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Scent</td>\n",
       "      <td>Scent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sheet_Names Catalog_Features\n",
       "0  Main_Category    Main_Category\n",
       "1   Sub_Category     Sub_Category\n",
       "2           Size             Size\n",
       "3            Fit              Fit\n",
       "4          Color            Color\n",
       "5         Design           Design\n",
       "6       Material         Material\n",
       "7          Scent            Scent"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get lists of code sheets and catalog features\n",
    "code_sheet_list = list(tables.keys())[2:]  # List of sheet names\n",
    "catalog_feature_list = list(tables['Product_Catalog'].columns[1:]) #list of features from Product Catalog sheet excluding first column\n",
    "\n",
    "# remove \"Name\" from catalog_feature_list if present\n",
    "if \"Name\" in catalog_feature_list:\n",
    "    catalog_feature_list.remove(\"Name\")\n",
    "\n",
    "\n",
    "# sanity check: make sure both lists match exactly\n",
    "if set(code_sheet_list) == set(catalog_feature_list):\n",
    "    print(\"Sheet names and catalog features MATCH exactly!\")\n",
    "else:\n",
    "    raise AssertionError(\"Sheet names and catalog features DO NOT match!\")\n",
    "\n",
    "# for visual reference, create a DF to show matching sheets and features\n",
    "matching_df = pd.DataFrame({\n",
    "    'Sheet_Names': code_sheet_list,\n",
    "    'Catalog_Features': catalog_feature_list\n",
    "})\n",
    "matching_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7f2d0a",
   "metadata": {},
   "source": [
    "## Permutation logic\n",
    "Generate dictionaries all possible permutations of a given prodcut model, extracting the feature, prefix, and index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import re\n",
    "\n",
    "def generate_permutations(row):\n",
    "    \"\"\"\n",
    "    For a given product model row, generate all possible permutations of feature combinations.\n",
    "    Returns a list of dictionaries, where each dictionary represents one SKU permutation.\n",
    "    Each value in the dict is [value_name, prefix, index] (as strings).\n",
    "    For AND cases (semicolon), indexes are concatenated and value names are simplified.\n",
    "    Features with index '0' or prefix ending in 'NAN' are excluded (not applicable values).\n",
    "    \"\"\"\n",
    "\n",
    "    # Size abbreviation to full name mapping\n",
    "    size_mapping = {\n",
    "        'CS': 'Child Small',\n",
    "        'CM': 'Child Medium',\n",
    "        'CL': 'Child Large',\n",
    "        'XS': 'Extra Small',\n",
    "        'S': 'Small',\n",
    "        'M': 'Medium',\n",
    "        'L': 'Large',\n",
    "        'XL': 'Extra Large',\n",
    "        '2XL': 'Double Extra Large',\n",
    "        '3XL': 'Triple Extra Large',\n",
    "        '4XL': 'Quadruple Extra Large',\n",
    "        '5XL': 'Quintuple Extra Large',\n",
    "        'S/M': 'Small to Medium',\n",
    "        'L/XL': 'Large to Extra Large',\n",
    "        'NA': 'Not Applicable'\n",
    "    }\n",
    "    \n",
    "    # Dictionary to hold all feature values for this product model\n",
    "    feature_options = {}\n",
    "    \n",
    "    for feature in catalog_feature_list:\n",
    "        feature_values = row[feature]\n",
    "        \n",
    "        # Check if feature_values contains comma or semicolon (is a list)\n",
    "        if isinstance(feature_values, str):\n",
    "            if ',' in feature_values:\n",
    "                # Comma-separated = \"OR\" - these create separate permutations\n",
    "                values = [v.strip() for v in feature_values.split(',')]\n",
    "                \n",
    "                # If this is Size feature, map abbreviations to full names\n",
    "                if feature == 'Size':\n",
    "                    values = [size_mapping.get(v, v) for v in values]\n",
    "                \n",
    "                feature_options[feature] = {\n",
    "                    'values': values,\n",
    "                    'type': 'OR'\n",
    "                }\n",
    "            elif ';' in feature_values:\n",
    "                # Semicolon-separated = \"AND\" - these must all appear together\n",
    "                values = [v.strip() for v in feature_values.split(';')]\n",
    "                \n",
    "                # If this is Size feature, map abbreviations to full names\n",
    "                if feature == 'Size':\n",
    "                    values = [size_mapping.get(v, v) for v in values]\n",
    "                \n",
    "                feature_options[feature] = {\n",
    "                    'values': values,\n",
    "                    'type': 'AND'\n",
    "                }\n",
    "            else:\n",
    "                # Single value\n",
    "                value = feature_values\n",
    "                \n",
    "                # If this is Size feature, map abbreviation to full name\n",
    "                if feature == 'Size':\n",
    "                    value = size_mapping.get(value.strip(), value)\n",
    "                \n",
    "                feature_options[feature] = {\n",
    "                    'values': [value],\n",
    "                    'type': 'SINGLE'\n",
    "                }\n",
    "        else:\n",
    "            # Non-string value (e.g., NaN, number) - treat as single value\n",
    "            feature_options[feature] = {\n",
    "                'values': [feature_values] if not pd.isna(feature_values) else [''],\n",
    "                'type': 'SINGLE'\n",
    "            }\n",
    "    \n",
    "    # Helper function to get prefix and index for a feature value\n",
    "    def get_value_info(feature, value_name):\n",
    "        \"\"\"Returns [value_name, prefix, index] for a given feature value.\"\"\"\n",
    "        code_sheet = tables[feature]\n",
    "        matching_rows = code_sheet.loc[code_sheet[\"Name\"] == value_name]\n",
    "        \n",
    "        if not matching_rows.empty:\n",
    "            code_index = matching_rows.index[0]\n",
    "            prefix = code_sheet.at[code_index, \"Prefix\"]\n",
    "            # Convert index to string (no padding)\n",
    "            index_str = str(code_index)\n",
    "            return [value_name, prefix, index_str]\n",
    "        else:\n",
    "            # If not found, return empty prefix and empty index\n",
    "            return [value_name, \"\", \"\"]\n",
    "    \n",
    "    # Helper function to check if a feature should be excluded\n",
    "    def is_not_applicable(value_info):\n",
    "        \"\"\"Returns True if the feature is 'Not Applicable' (index 0 or prefix ends with NAN)\"\"\"\n",
    "        index = value_info[2]\n",
    "        prefix = value_info[1]\n",
    "        return index == '0' or prefix.endswith('NAN')\n",
    "    \n",
    "    # Helper function to simplify value names for AND cases\n",
    "    def simplify_and_values(value_names):\n",
    "        \"\"\"\n",
    "        Simplifies multiple value names by finding common parts.\n",
    "        E.g., ['Bandit Truck Icon', 'Bandit Truck Wordmark'] -> 'Bandit Truck Icon AND Wordmark'\n",
    "        \"\"\"\n",
    "        if len(value_names) == 1:\n",
    "            return value_names[0]\n",
    "        \n",
    "        # Find common prefix among all names\n",
    "        common_prefix = \"\"\n",
    "        min_len = min(len(name) for name in value_names)\n",
    "        \n",
    "        for i in range(min_len):\n",
    "            if all(name[i] == value_names[0][i] for name in value_names):\n",
    "                common_prefix += value_names[0][i]\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        # Clean up common prefix (remove trailing spaces/incomplete words)\n",
    "        common_prefix = common_prefix.rstrip()\n",
    "        \n",
    "        # Extract unique parts from each name\n",
    "        unique_parts = []\n",
    "        for name in value_names:\n",
    "            unique_part = name[len(common_prefix):].strip()\n",
    "            if unique_part:\n",
    "                unique_parts.append(unique_part)\n",
    "        \n",
    "        # Construct simplified name\n",
    "        if common_prefix and unique_parts:\n",
    "            return f\"{common_prefix} {' AND '.join(unique_parts)}\"\n",
    "        else:\n",
    "            return ' AND '.join(value_names)\n",
    "    \n",
    "    # Separate features by type\n",
    "    or_features = {k: v['values'] for k, v in feature_options.items() if v['type'] == 'OR'}\n",
    "    and_features = {k: v['values'] for k, v in feature_options.items() if v['type'] == 'AND'}\n",
    "    single_features = {k: v['values'] for k, v in feature_options.items() if v['type'] == 'SINGLE'}\n",
    "    \n",
    "    # Build permutation components\n",
    "    permutation_dict = {}\n",
    "    \n",
    "    # Add single features (these don't multiply permutations)\n",
    "    for feature, values in single_features.items():\n",
    "        permutation_dict[feature] = values\n",
    "    \n",
    "    # Add OR features (these DO multiply permutations)\n",
    "    for feature, values in or_features.items():\n",
    "        permutation_dict[feature] = values\n",
    "    \n",
    "    # Generate all permutations using cartesian product\n",
    "    feature_names = list(permutation_dict.keys())\n",
    "    feature_value_lists = [permutation_dict[f] for f in feature_names]\n",
    "    \n",
    "    permutations = []\n",
    "    for combo in product(*feature_value_lists):\n",
    "        perm = {}\n",
    "        \n",
    "        # For each feature in this combination, get [value, prefix, index]\n",
    "        for feature, value_name in zip(feature_names, combo):\n",
    "            value_info = get_value_info(feature, value_name)\n",
    "            \n",
    "            # Skip if this is a \"Not Applicable\" value\n",
    "            if not is_not_applicable(value_info):\n",
    "                perm[feature] = value_info\n",
    "        \n",
    "        # Add AND features (combine into single [simplified_name, prefix, concatenated_indexes])\n",
    "        for feature, values in and_features.items():\n",
    "            # Get info for all values\n",
    "            value_infos = [get_value_info(feature, val) for val in values]\n",
    "            \n",
    "            # Check if any of the AND values are \"Not Applicable\"\n",
    "            if any(is_not_applicable(info) for info in value_infos):\n",
    "                continue  # Skip this entire AND feature\n",
    "            \n",
    "            # Simplify the value name\n",
    "            simplified_name = simplify_and_values([info[0] for info in value_infos])\n",
    "            \n",
    "            # Use first prefix (assuming they're all the same)\n",
    "            prefix = value_infos[0][1] if value_infos else \"\"\n",
    "            \n",
    "            # Concatenate indexes (no padding)\n",
    "            concatenated_index = \"\".join([info[2] for info in value_infos])\n",
    "            \n",
    "            perm[feature] = [simplified_name, prefix, concatenated_index]\n",
    "        \n",
    "        # Add the product name\n",
    "        perm['Name'] = row['Name']\n",
    "        \n",
    "        permutations.append(perm)\n",
    "    \n",
    "    return permutations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "175bc2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Bandit Truck Logo Tee\n",
      "Number of permutations: 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test permutation generation with arbitrary row\n",
    "test_row = tables['Product_Catalog'].iloc[2]\n",
    "permutations = generate_permutations(test_row)\n",
    "\n",
    "print(f\"Product: {test_row['Name']}\")\n",
    "print(f\"Number of permutations: {len(permutations)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb95a22b",
   "metadata": {},
   "source": [
    "## SKU number generation\n",
    "Generate unique SKUs based on the feature prefixes and indices. Use a timestamp with millisecond accuracy as a contingincy in the case of duplicate SKUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "f8ad1cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a unique sku based on prefixes and indexes\n",
    "from datetime import datetime\n",
    "import base36\n",
    "\n",
    "def generate_sku(dict, add_timestamp=False):\n",
    "    \"\"\"\n",
    "    Generate a SKU from a permutation dictionary.\n",
    "    \n",
    "    Parameters:\n",
    "    - dict: permutation dictionary with feature info\n",
    "    - add_timestamp: if True, adds a compact timestamp suffix for guaranteed uniqueness\n",
    "    \"\"\"\n",
    "    model_name = dict['Name']\n",
    "    part_list = []\n",
    "    sku_prefix = \"\"\n",
    "\n",
    "    # Create sku prefix for main prefix, and sub prefix and index\n",
    "    sku_prefix += dict['Main_Category'][1]\n",
    "    sku_prefix += dict['Sub_Category'][1]\n",
    "    sku_prefix += dict['Sub_Category'][2]\n",
    "    part_list.append(sku_prefix)\n",
    "\n",
    "\n",
    "    # iterate the rest of the dict items\n",
    "    for i, key in enumerate(dict.keys()):\n",
    "        if i >= 2 and key != \"Name\":  # only the third and proceeding items, exclude \"Name\"\n",
    "            # print(f\"key: {key}, value: {dict[key]}\")\n",
    "            part = dict[key][1] + dict[key][2]\n",
    "            part_list.append(part)\n",
    "\n",
    "    # Base SKU\n",
    "    sku = \"-\".join(part_list)\n",
    "    \n",
    "    # Add timestamp suffix if requested\n",
    "    if add_timestamp:\n",
    "        now = datetime.now()\n",
    "        unix_ms = int(now.timestamp() * 1000)\n",
    "        compact_time = base36.dumps(unix_ms)[-6:].upper()\n",
    "        \n",
    "        sku = f\"{sku}-{compact_time}\"\n",
    "    \n",
    "    print(f\"Sku generated for {model_name} variant: {sku}\")\n",
    "\n",
    "    return (model_name, sku)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "50268669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sku generated for Bandit Truck Logo Tee variant: MAUS1-FT1-CL2-MAT1-SZ5-D45-8G0CC5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on an arbitrary permutation\n",
    "model, sku = generate_sku(permutations[0],True)\n",
    "\n",
    "len(sku)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b97c32",
   "metadata": {},
   "source": [
    "# SKU number persistance\n",
    "Generate and write generate SKUs to a csv file with other product details. \n",
    "Prevent duplicate skus by checking the existing CSV and regenerate skus with timestamp based unique identifiers in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "92f0bfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV already exists at: Results/catalog_skus.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def initialize_output_csv(output_path='Results/catalog_skus.csv'):\n",
    "    \"\"\"\n",
    "    Create a CSV template with the same structure as Product_Catalog if it doesn't exist.\n",
    "    If the file already exists, do nothing.\n",
    "    Adds a 'SKU' column which will serve as the index for unique identification.\n",
    "    \n",
    "    Parameters:\n",
    "    - output_path: path where the CSV should be created\n",
    "    \n",
    "    Returns:\n",
    "    - True if file was created, False if it already existed\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if file already exists\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"CSV already exists at: {output_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Get the column names from Product_Catalog and add SKU column\n",
    "    template_columns = ['SKU'] + tables['Product_Catalog'].columns.tolist()\n",
    "    \n",
    "    # Create an empty DataFrame with these columns\n",
    "    template_df = pd.DataFrame(columns=template_columns)\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    # Save to CSV with SKU as index\n",
    "    template_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"Created new CSV template with columns: {template_columns}\")\n",
    "    print(f\"Saved to: {output_path}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Test the function\n",
    "initialize_output_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "6215c819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV columns: ['SKU', 'Index', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "\n",
      "First few rows:\n",
      "Empty DataFrame\n",
      "Columns: [SKU, Index, Main_Category, Sub_Category, Name, Size, Fit, Color, Design, Material, Scent]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check the CSV structure\n",
    "if os.path.exists('Results/catalog_skus.csv'):\n",
    "    test_df = pd.read_csv('Results/catalog_skus.csv')\n",
    "    print(f\"CSV columns: {test_df.columns.tolist()}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6725a1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
