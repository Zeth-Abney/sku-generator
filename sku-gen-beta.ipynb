{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb73f2f1",
   "metadata": {},
   "source": [
    "# Sku Generator Beta Testing Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4993eae4",
   "metadata": {},
   "source": [
    "Read Apple Numbers file with multiple sheets into Pandas Data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee285f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numbers_parser import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e357ae0d",
   "metadata": {},
   "source": [
    "## Data Preparation and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24a4466e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Product_Catalog:\n",
      "   Index Main Category           Sub Category                       Name  \\\n",
      "0    0.0         Shirt              Tee Shirt         Bandit Banquet Tee   \n",
      "1    1.0         Shirt              Tee Shirt    Bandit Truck Wreath Tee   \n",
      "2    2.0         Shirt              Tee Shirt      Bandit Truck Logo Tee   \n",
      "3    3.0         Shirt              Tee Shirt              Legendary Tee   \n",
      "4    4.0         Shirt  Long Sleeve Tee Shirt  Legendary Long Sleeve Tee   \n",
      "\n",
      "                                                Size     Fit  \\\n",
      "0  Child Small,Child Medium,Child Large,Extra Sma...  Unisex   \n",
      "1  Child Small,Child Medium,Child Large,Extra Sma...  Unisex   \n",
      "2  Child Small,Child Medium,Child Large,Extra Sma...  Unisex   \n",
      "3  Child Small,Child Medium,Child Large,Extra Sma...  Unisex   \n",
      "4  Child Small,Child Medium,Child Large,Extra Sma...  Unisex   \n",
      "\n",
      "                      Color                                   Design Material  \\\n",
      "0                    Yellow                           Bandit Banquet   Cotton   \n",
      "1                     Black                        Bandit Truck Icon   Cotton   \n",
      "2                     Black  Bandit Truck Icon;Bandit Truck Wordmark   Cotton   \n",
      "3  White, Blue, Gray, Black        Legendary Icon;Legendary Wordmark   Cotton   \n",
      "4                      Blue        Legendary Icon;Legendary Wordmark    Nylon   \n",
      "\n",
      "            Scent  \n",
      "0  Not Applicable  \n",
      "1  Not Applicable  \n",
      "2  Not Applicable  \n",
      "3  Not Applicable  \n",
      "4  Not Applicable  \n",
      "\n",
      "Size:\n",
      "   Code Prefix            Name           Comments\n",
      "0   0.0   SNAN  Not Applicable  Non Apparel Items\n",
      "1   1.0     CS     Child Small               None\n",
      "2   2.0     CM    Child Medium               None\n",
      "3   3.0     CL     Child Large               None\n",
      "4   4.0     XS     Extra Small               None\n",
      "\n",
      "Prefix_Codes:\n",
      "  Prefix         Feature     Comments\n",
      "0    NAN  Not Applicable         None\n",
      "1     MA   Main Category      Apparel\n",
      "2     MB   Main Category  Accessories\n",
      "3     MP   Main Category        Parts\n",
      "4     US    Sub Category       Shirts\n",
      "\n",
      "Main_Category:\n",
      "   Code Prefix            Name Comments\n",
      "0   0.0   MNAN  Not Applicable     None\n",
      "1   1.0    SRT           Shirt     None\n",
      "2   2.0    OUT       Outerwear     None\n",
      "3   3.0    HED        Headwear     None\n",
      "4   4.0    ACC     Accessories     None\n",
      "\n",
      "Sub_Category:\n",
      "    Code Prefix                   Name Main Category Comments\n",
      "0    0.0   UNAN         Not Applicable          None     None\n",
      "1  101.0    TEE              Tee Shirt         Shirt     None\n",
      "2  102.0    LNG  Long Sleeve Tee Shirt         Shirt     None\n",
      "3  103.0    PLO                   Polo         Shirt     None\n",
      "4  201.0    SWT                Sweater     Outerwear     None\n",
      "\n",
      "Fit:\n",
      "   Code Prefix            Name Comments\n",
      "0   0.0  FTNAN  Not Applicable     None\n",
      "1   1.0    USX          Unisex     None\n",
      "2   2.0    MLE            Male     None\n",
      "3   3.0    FEM          Female     None\n",
      "\n",
      "Color:\n",
      "   Code Prefix    Name Comments\n",
      "0   0.0  CLNAN      NA     None\n",
      "1   1.0    WHT   White     None\n",
      "2   2.0    BLK   Black     None\n",
      "3   3.0    GRY    Gray     None\n",
      "4   4.0    YLW  Yellow     None\n",
      "\n",
      "Design:\n",
      "   Code Prefix                Name Comments\n",
      "0   0.0   DNAN      Not Applicable     None\n",
      "1   1.0   BDBQ      Bandit Banquet     None\n",
      "2   2.0    LGI      Legendary Icon     None\n",
      "3   3.0    LGW  Legendary Wordmark     None\n",
      "4   4.0    BTI   Bandit Truck Icon     None\n",
      "\n",
      "Material:\n",
      "   Code  Prefix            Name Comments\n",
      "0   0.0  MATNAN  Not Applicable     None\n",
      "1   1.0     CTN          Cotton     None\n",
      "2   2.0     NLN           Nylon     None\n",
      "3   3.0     BLD           Blend     None\n",
      "4   4.0     LTR         Leather     None\n",
      "\n",
      "Scent:\n",
      "   Code Prefix              Name Comments\n",
      "0   0.0  STNAN    Not Applicable     None\n",
      "1   1.0    CLL  Callahan Leather     None\n",
      "2   2.0    VLL   Vanilla Leather     None\n",
      "3   3.0    CBC    Cowboy Cologne     None\n",
      "\n",
      "Tables loaded:\n",
      "- Product_Catalog\n",
      "- Size\n",
      "- Prefix_Codes\n",
      "- Main_Category\n",
      "- Sub_Category\n",
      "- Fit\n",
      "- Color\n",
      "- Design\n",
      "- Material\n",
      "- Scent\n"
     ]
    }
   ],
   "source": [
    "def load_catalog_data(file_path=\"\",debug=False):\n",
    "    \"\"\"\n",
    "    Load Apple Numbers file with multiple sheets into Pandas DataFrames.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path: path to the Numbers file\n",
    "    \n",
    "    Returns:\n",
    "    - tables: dictionary of DataFrames, one for each sheet/table in the Numbers file\n",
    "    \"\"\"\n",
    "    # Read the Numbers file\n",
    "    doc = Document(file_path)\n",
    "    sheets = doc.sheets\n",
    "    tables = {}\n",
    "\n",
    "    # Extract each sheet as a separate dataframe\n",
    "    for sheet in sheets:\n",
    "        for table in sheet.tables:\n",
    "            table_name = table.name.replace(\" \", \"_\")\n",
    "            data = table.rows(values_only=True)\n",
    "            tables[table_name] = pd.DataFrame(data[1:], columns=data[0])\n",
    "\n",
    "    # Access individual dataframes\n",
    "    if debug:\n",
    "        for name, df in tables.items():\n",
    "            print(f\"\\n{name}:\")\n",
    "            print(df.head())\n",
    "\n",
    "    # For Product Catalog sheet replace spaces with underscores in column names\n",
    "    tables['Product_Catalog'].columns = tables['Product_Catalog'].columns.str.replace(' ', '_')\n",
    "    \n",
    "    return tables\n",
    "\n",
    "# Load the data\n",
    "file_path = \"CHARTS/catalog.numbers\"\n",
    "tables = load_catalog_data(file_path,True)\n",
    "\n",
    "# Show list of table names\n",
    "print(\"\\nTables loaded:\")\n",
    "for table_name in tables.keys():\n",
    "    print(f\"- {table_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c526a54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet names and catalog features MATCH exactly!\n",
      "     Sheet_Names Catalog_Features\n",
      "0           Size    Main_Category\n",
      "1  Main_Category     Sub_Category\n",
      "2   Sub_Category             Size\n",
      "3            Fit              Fit\n",
      "4          Color            Color\n",
      "5         Design           Design\n",
      "6       Material         Material\n",
      "7          Scent            Scent\n"
     ]
    }
   ],
   "source": [
    "def validate_catalog_features(data=\"\",debug=False):\n",
    "    \"\"\"\n",
    "    Validate that code sheet names match catalog features and extract the feature list.\n",
    "    \n",
    "    Parameters:\n",
    "    - tables: dictionary of DataFrames from load_catalog_data()\n",
    "    \n",
    "    Returns:\n",
    "    - tuple: (code_sheet_list, catalog_feature_list)\n",
    "    \n",
    "    Raises:\n",
    "    - AssertionError if sheet names don't match catalog features\n",
    "    \"\"\"\n",
    "    # get lists of code sheets and catalog features\n",
    "    code_sheet_list = list(tables.keys())[1:]  # List of sheet names (skip Product_Catalog)\n",
    "    catalog_feature_list = list(tables['Product_Catalog'].columns[1:])  # list of features from Product Catalog sheet excluding first column (Index)\n",
    "\n",
    "    # remove \"Name\" from catalog_feature_list if present\n",
    "    if \"Name\" in catalog_feature_list:\n",
    "        catalog_feature_list.remove(\"Name\")\n",
    "    \n",
    "    # remove \"Prefix_Codes\" from code_sheet_list if present (it's a reference table, not a feature)\n",
    "    if \"Prefix_Codes\" in code_sheet_list:\n",
    "        code_sheet_list.remove(\"Prefix_Codes\")\n",
    "\n",
    "    # sanity check: make sure both lists match exactly\n",
    "    if set(code_sheet_list) == set(catalog_feature_list):\n",
    "        print(\"Sheet names and catalog features MATCH exactly!\")\n",
    "    else:\n",
    "        raise AssertionError(\"Sheet names and catalog features DO NOT match!\")\n",
    "\n",
    "    # for visual reference, create a DF to show matching sheets and features\n",
    "    matching_df = pd.DataFrame({\n",
    "        'Sheet_Names': code_sheet_list,\n",
    "        'Catalog_Features': catalog_feature_list\n",
    "    })\n",
    "    if debug:\n",
    "        print(matching_df)\n",
    "    \n",
    "    return code_sheet_list, catalog_feature_list\n",
    "\n",
    "# Validate and extract feature lists\n",
    "code_sheet_list, catalog_feature_list = validate_catalog_features(tables,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d83c9fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code sheets: ['Size', 'Prefix_Codes', 'Main_Category', 'Sub_Category', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "\n",
      "Catalog features: ['Main_Category', 'Sub_Category', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "\n",
      "In code_sheet_list but not in catalog_feature_list: {'Prefix_Codes'}\n",
      "In catalog_feature_list but not in code_sheet_list: set()\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check what columns are in Product_Catalog vs what sheets exist\n",
    "code_sheet_list = list(tables.keys())[1:]  # Skip Product_Catalog\n",
    "catalog_feature_list = list(tables['Product_Catalog'].columns[1:])  # Skip Index\n",
    "if \"Name\" in catalog_feature_list:\n",
    "    catalog_feature_list.remove(\"Name\")\n",
    "\n",
    "print(\"Code sheets:\", code_sheet_list)\n",
    "print(\"\\nCatalog features:\", catalog_feature_list)\n",
    "print(\"\\nIn code_sheet_list but not in catalog_feature_list:\", set(code_sheet_list) - set(catalog_feature_list))\n",
    "print(\"In catalog_feature_list but not in code_sheet_list:\", set(catalog_feature_list) - set(code_sheet_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea560f8d",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1eb8435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All product names are unique, total batches to process: 18\n"
     ]
    }
   ],
   "source": [
    "# create a list of batch names from the set of unique Name field values in the product catalog\n",
    "\n",
    "def prepare_batches(data):\n",
    "    \"\"\"\n",
    "    Get unique product names from the Product Catalog and check for duplicates.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: DataFrame (Product_Catalog)\n",
    "    \n",
    "    Returns:\n",
    "    - list of unique product names (batch names)\n",
    "    \"\"\"\n",
    "    # Get unique names from the Name column\n",
    "    name_field_list = data['Name'].tolist()\n",
    "    name_field_set = set(name_field_list)\n",
    "    \n",
    "    # Check for duplicates by comparing list length to set length\n",
    "    has_duplicates = len(name_field_list) != len(name_field_set)\n",
    "    \n",
    "    if has_duplicates:\n",
    "        duplicate_list = []\n",
    "        print(f\"WARNING: Found {len(name_field_list) - len(name_field_set)} duplicate name(s)\")\n",
    "        # Find and print duplicates\n",
    "        seen = {}\n",
    "        for idx, name in enumerate(name_field_list):\n",
    "            if name in seen:\n",
    "                duplicate_list.append((name, seen[name], idx))\n",
    "            else:\n",
    "                seen[name] = idx\n",
    "        \n",
    "        # Print the duplicates\n",
    "        print(\"\\nDuplicate Names Found:\")\n",
    "        for name, first_idx, second_idx in duplicate_list:\n",
    "            print(f\"  '{name}' at indexes {first_idx} and {second_idx}\")\n",
    "    else:\n",
    "        print(f\"All product names are unique, total batches to process: {len(name_field_list)}\")\n",
    "    \n",
    "    return list(name_field_set)\n",
    "\n",
    "batch_name_list = prepare_batches(tables['Product_Catalog'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7f2d0a",
   "metadata": {},
   "source": [
    "### Permutation logic\n",
    "Generate dictionaries all possible permutations of a given prodcut model, extracting the feature, prefix, and index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Bandit Truck Logo Tee\n",
      "Number of permutations: 12\n",
      "\n",
      "Data imput type <class 'pandas.core.series.Series'>\n",
      "Data output type: <class 'list'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import re\n",
    "\n",
    "def generate_permutations(batch_name=\"\",debug=False):\n",
    "    \"\"\"\n",
    "    For a given product model (ie batch_name), generate all possible permutations of feature combinations.\n",
    "    Returns a list of dictionaries, where each dictionary represents one permutation.\n",
    "    Each value in the dict is [value_name, prefix, index] (as strings).\n",
    "    Prefix and index are from the corresponding code sheet.\n",
    "    For AND cases (semicolon), indexes are concatenated and value names are simplified.\n",
    "    Features with index '0' or prefix ending in 'NAN' are excluded (not applicable values).\n",
    "\n",
    "    Parameters:\n",
    "    - batch_name: String representing a row from Product_Catalog DataFrame\n",
    "    - debug: Boolean flag to enable debug printing\n",
    "    \n",
    "    Returns:\n",
    "    - List of dictionaries, each representing a permutation\n",
    "    \"\"\"\n",
    "\n",
    "    # Size abbreviation to full name mapping\n",
    "    size_mapping = {\n",
    "        'CS': 'Child Small',\n",
    "        'CM': 'Child Medium',\n",
    "        'CL': 'Child Large',\n",
    "        'XS': 'Extra Small',\n",
    "        'S': 'Small',\n",
    "        'M': 'Medium',\n",
    "        'L': 'Large',\n",
    "        'XL': 'Extra Large',\n",
    "        '2XL': 'Double Extra Large',\n",
    "        '3XL': 'Triple Extra Large',\n",
    "        '4XL': 'Quadruple Extra Large',\n",
    "        '5XL': 'Quintuple Extra Large',\n",
    "        'S/M': 'Small to Medium',\n",
    "        'L/XL': 'Large to Extra Large',\n",
    "        'NA': 'Not Applicable'\n",
    "    }\n",
    "    \n",
    "    # Dictionary to hold all feature values for this product model\n",
    "    feature_options = {}\n",
    "    \n",
    "    for feature in catalog_feature_list:\n",
    "        feature_values = batch_name[feature]\n",
    "        \n",
    "        # Check if feature_values contains comma or semicolon (is a list)\n",
    "        if isinstance(feature_values, str):\n",
    "            if ',' in feature_values:\n",
    "                # Comma-separated = \"OR\" - these create separate permutations\n",
    "                values = [v.strip() for v in feature_values.split(',')]\n",
    "                \n",
    "                # If this is Size feature, map abbreviations to full names\n",
    "                if feature == 'Size':\n",
    "                    values = [size_mapping.get(v, v) for v in values]\n",
    "                \n",
    "                feature_options[feature] = {\n",
    "                    'values': values,\n",
    "                    'type': 'OR'\n",
    "                }\n",
    "            elif ';' in feature_values:\n",
    "                # Semicolon-separated = \"AND\" - these must all appear together\n",
    "                values = [v.strip() for v in feature_values.split(';')]\n",
    "                \n",
    "                # If this is Size feature, map abbreviations to full names\n",
    "                if feature == 'Size':\n",
    "                    values = [size_mapping.get(v, v) for v in values]\n",
    "                \n",
    "                feature_options[feature] = {\n",
    "                    'values': values,\n",
    "                    'type': 'AND'\n",
    "                }\n",
    "            else:\n",
    "                # Single value\n",
    "                value = feature_values\n",
    "                \n",
    "                # If this is Size feature, map abbreviation to full name\n",
    "                if feature == 'Size':\n",
    "                    value = size_mapping.get(value.strip(), value)\n",
    "                \n",
    "                feature_options[feature] = {\n",
    "                    'values': [value],\n",
    "                    'type': 'SINGLE'\n",
    "                }\n",
    "        else:\n",
    "            # Non-string value (e.g., NaN, number) - treat as single value\n",
    "            feature_options[feature] = {\n",
    "                'values': [feature_values] if not pd.isna(feature_values) else [''],\n",
    "                'type': 'SINGLE'\n",
    "            }\n",
    "    \n",
    "    # Helper function to get prefix and index for a feature value\n",
    "    def get_value_info(feature, value_name):\n",
    "        \"\"\"Returns [value_name, prefix, index] for a given feature value.\"\"\"\n",
    "        code_sheet = tables[feature]\n",
    "        matching_rows = code_sheet.loc[code_sheet[\"Name\"] == value_name]\n",
    "        \n",
    "        if not matching_rows.empty:\n",
    "            code_index = matching_rows.index[0]\n",
    "            prefix = code_sheet.at[code_index, \"Prefix\"]\n",
    "            # Convert index to string (no padding)\n",
    "            index_str = str(code_index)\n",
    "            return [value_name, prefix, index_str]\n",
    "        else:\n",
    "            # If not found, return empty prefix and empty index\n",
    "            return [value_name, \"\", \"\"]\n",
    "    \n",
    "    # Helper function to check if a feature should be excluded\n",
    "    def is_not_applicable(value_info):\n",
    "        \"\"\"Returns True if the feature is 'Not Applicable' (index 0 or prefix ends with NAN)\"\"\"\n",
    "        index = value_info[2]\n",
    "        prefix = value_info[1]\n",
    "        return index == '0' or prefix.endswith('NAN')\n",
    "    \n",
    "    # Helper function to simplify value names for AND cases\n",
    "    def simplify_and_values(value_names):\n",
    "        \"\"\"\n",
    "        Simplifies multiple value names by finding common parts.\n",
    "        E.g., ['Bandit Truck Icon', 'Bandit Truck Wordmark'] -> 'Bandit Truck Icon AND Wordmark'\n",
    "        \"\"\"\n",
    "        if len(value_names) == 1:\n",
    "            return value_names[0]\n",
    "        \n",
    "        # Find common prefix among all names\n",
    "        common_prefix = \"\"\n",
    "        min_len = min(len(name) for name in value_names)\n",
    "        \n",
    "        for i in range(min_len):\n",
    "            if all(name[i] == value_names[0][i] for name in value_names):\n",
    "                common_prefix += value_names[0][i]\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        # Clean up common prefix (remove trailing spaces/incomplete words)\n",
    "        common_prefix = common_prefix.rstrip()\n",
    "        \n",
    "        # Extract unique parts from each name\n",
    "        unique_parts = []\n",
    "        for name in value_names:\n",
    "            unique_part = name[len(common_prefix):].strip()\n",
    "            if unique_part:\n",
    "                unique_parts.append(unique_part)\n",
    "        \n",
    "        # Construct simplified name\n",
    "        if common_prefix and unique_parts:\n",
    "            return f\"{common_prefix} {' AND '.join(unique_parts)}\"\n",
    "        else:\n",
    "            return ' AND '.join(value_names)\n",
    "    \n",
    "    # Separate features by type\n",
    "    or_features = {k: v['values'] for k, v in feature_options.items() if v['type'] == 'OR'}\n",
    "    and_features = {k: v['values'] for k, v in feature_options.items() if v['type'] == 'AND'}\n",
    "    single_features = {k: v['values'] for k, v in feature_options.items() if v['type'] == 'SINGLE'}\n",
    "    \n",
    "    # Build permutation components\n",
    "    permutation_dict = {}\n",
    "    \n",
    "    # Add single features (these don't multiply permutations)\n",
    "    for feature, values in single_features.items():\n",
    "        permutation_dict[feature] = values\n",
    "    \n",
    "    # Add OR features (these DO multiply permutations)\n",
    "    for feature, values in or_features.items():\n",
    "        permutation_dict[feature] = values\n",
    "    \n",
    "    # Generate all permutations using cartesian product\n",
    "    feature_names = list(permutation_dict.keys())\n",
    "    feature_value_lists = [permutation_dict[f] for f in feature_names]\n",
    "    \n",
    "    permutations = []\n",
    "    for combo in product(*feature_value_lists):\n",
    "        perm = {}\n",
    "        \n",
    "        # For each feature in this combination, get [value, prefix, index]\n",
    "        for feature, value_name in zip(feature_names, combo):\n",
    "            value_info = get_value_info(feature, value_name)\n",
    "            \n",
    "            # Skip if this is a \"Not Applicable\" value\n",
    "            if not is_not_applicable(value_info):\n",
    "                perm[feature] = value_info\n",
    "        \n",
    "        # Add AND features (combine into single [simplified_name, prefix, concatenated_indexes])\n",
    "        for feature, values in and_features.items():\n",
    "            # Get info for all values\n",
    "            value_infos = [get_value_info(feature, val) for val in values]\n",
    "            \n",
    "            # Check if any of the AND values are \"Not Applicable\"\n",
    "            if any(is_not_applicable(info) for info in value_infos):\n",
    "                continue  # Skip this entire AND feature\n",
    "            \n",
    "            # Simplify the value name\n",
    "            simplified_name = simplify_and_values([info[0] for info in value_infos])\n",
    "            \n",
    "            # Use first prefix (assuming they're all the same)\n",
    "            prefix = value_infos[0][1] if value_infos else \"\"\n",
    "            \n",
    "            # Concatenate indexes (no padding)\n",
    "            concatenated_index = \"\".join([info[2] for info in value_infos])\n",
    "            \n",
    "            perm[feature] = [simplified_name, prefix, concatenated_index]\n",
    "        \n",
    "        # Add the product name\n",
    "        perm['Name'] = batch_name['Name']\n",
    "        \n",
    "        permutations.append(perm)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Product: {batch_name['Name']}\")\n",
    "        print(f\"Number of permutations: {len(permutations)}\\n\")\n",
    "        print(f\"Data imput type {type(batch_name)}\")\n",
    "        print(f\"Data output type: {type(permutations)}\\n\")\n",
    "    \n",
    "    return permutations\n",
    "\n",
    "# Test permutation generation with arbitrary row\n",
    "test_row = tables['Product_Catalog'].iloc[2]\n",
    "permutations = generate_permutations(test_row,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb95a22b",
   "metadata": {},
   "source": [
    "### SKU number generation\n",
    "Generate unique SKUs based on the feature prefixes and indices. Use a timestamp with millisecond accuracy as a contingincy in the case of duplicate SKUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8ad1cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sku generated for\n",
      " Product Model: Bandit Truck Logo Tee\n",
      " variant: SRTTEE1-USX-BLK-CTN-CS-BTI\n",
      " SKU length: 26\n"
     ]
    }
   ],
   "source": [
    "# generate a unique sku based on prefixes and indexes\n",
    "from datetime import datetime\n",
    "from multiprocessing.util import debug\n",
    "import base36\n",
    "\n",
    "def generate_sku(dict, add_timestamp=False, debug=False):\n",
    "    \"\"\"\n",
    "    Generate a SKU from a permutation dictionary.\n",
    "    \n",
    "    Parameters:\n",
    "    - dict: permutation dictionary with feature info\n",
    "    - add_timestamp: if True, adds a compact timestamp suffix for guaranteed uniqueness\n",
    "\n",
    "    Returns:\n",
    "    - Tuple: model_name, sku\n",
    "    \"\"\"\n",
    "\n",
    "    model_name = dict['Name']\n",
    "    part_list = []\n",
    "    sku_prefix = \"\"\n",
    "\n",
    "    # Create sku prefix for main prefix, and sub prefix and index\n",
    "    sku_prefix += dict['Main_Category'][1]\n",
    "    sku_prefix += dict['Sub_Category'][1]\n",
    "    sku_prefix += dict['Sub_Category'][2]\n",
    "    part_list.append(sku_prefix)\n",
    "\n",
    "\n",
    "    # iterate the rest of the dict items - now using only prefix for all features\n",
    "    for i, key in enumerate(dict.keys()):\n",
    "        if i >= 2 and key != \"Name\":  # only the third and proceeding items, exclude \"Name\"\n",
    "            # Use only the prefix (no index) for all features\n",
    "            part = dict[key][1]\n",
    "            # Skip empty prefixes\n",
    "            if part:\n",
    "                part_list.append(part)\n",
    "\n",
    "    # Base SKU\n",
    "    sku = \"-\".join(part_list)\n",
    "    \n",
    "    # Add timestamp suffix if requested\n",
    "    if add_timestamp:\n",
    "        now = datetime.now()\n",
    "        unix_ms = int(now.timestamp() * 1000)\n",
    "        compact_time = base36.dumps(unix_ms)[-6:].upper()\n",
    "        \n",
    "        sku = f\"{sku}-{compact_time}\"\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Sku generated for\\n Product Model: {model_name}\\n variant: {sku}\\n SKU length: {len(sku)}\")\n",
    "\n",
    "    return (model_name, sku)\n",
    "\n",
    "# test on an arbitrary permutation\n",
    "model, sku = generate_sku(permutations[0],False,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c3590d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test row (Product_Catalog data):\n",
      "Name: Bandit Truck Logo Tee\n",
      "Size value: 'Child Small,Child Medium,Child Large,Extra Small,Small,Medium,Large,Extra Large,Double Extra Large,Triple Extra Large,Quadruple Extra Large,Quintuple Extra Large'\n",
      "Size type: <class 'str'>\n",
      "\n",
      "Size table:\n",
      "    Code Prefix                   Name           Comments\n",
      "0    0.0   SNAN         Not Applicable  Non Apparel Items\n",
      "1    1.0     CS            Child Small               None\n",
      "2    2.0     CM           Child Medium               None\n",
      "3    3.0     CL            Child Large               None\n",
      "4    4.0     XS            Extra Small               None\n",
      "5    5.0      S                  Small               None\n",
      "6    6.0      M                 Medium               None\n",
      "7    7.0      L                  Large               None\n",
      "8    8.0     XL            Extra Large               None\n",
      "9    9.0    2XL     Double Extra Large               None\n",
      "10  10.0    3XL     Triple Extra Large               None\n",
      "11  11.0    4XL  Quadruple Extra Large               None\n",
      "12  12.0    5XL  Quintuple Extra Large               None\n",
      "13  13.0    S/M        Small to Medium          Hats Only\n",
      "14  14.0   L/XL   Large to Extra Large          Hats Only\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check what's in the Product_Catalog for this product\n",
    "print(\"Test row (Product_Catalog data):\")\n",
    "print(f\"Name: {test_row['Name']}\")\n",
    "print(f\"Size value: '{test_row['Size']}'\")\n",
    "print(f\"Size type: {type(test_row['Size'])}\")\n",
    "print(\"\\nSize table:\")\n",
    "print(tables['Size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b97c32",
   "metadata": {},
   "source": [
    "## SKU number persistance\n",
    "Generate and write generate SKUs to a csv file with other product details. \n",
    "Prevent duplicate skus by checking the existing CSV and regenerate skus with timestamp based unique identifiers in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f3a1c5",
   "metadata": {},
   "source": [
    "### Sequential Permutation and Procedural SKU Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d395c7",
   "metadata": {},
   "source": [
    "Generate a dictionary containing all permutations.\n",
    "\n",
    "Generate a SKU for each permutation and add it to the respective dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3635aa31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 'Legendary Distressed Hat': Generated 2 SKUs\n",
      "Batch 'Bandit Banquet Tee': Generated 12 SKUs\n",
      "Batch 'Bandit Truck Wreath Tee': Generated 12 SKUs\n",
      "Batch 'Bandit Truck Jacket': Generated 12 SKUs\n",
      "Batch 'Bandit Truck Flex Fit Hat': Generated 2 SKUs\n",
      "Batch 'Legendary Trucker Hat': Generated 2 SKUs\n",
      "Batch 'Collectible Gold Keychain': Generated 2 SKUs\n",
      "Batch 'Legendary Long Sleeve Tee': Generated 12 SKUs\n",
      "Batch 'Legendary Jacket': Generated 12 SKUs\n",
      "Batch 'Legendary Tee': Generated 48 SKUs\n",
      "Batch 'Bandit Truck Logo Tee': Generated 12 SKUs\n",
      "Batch 'Legendary Sweater': Generated 12 SKUs\n",
      "Batch 'Bandit Truck Wreath Sweater': Generated 12 SKUs\n",
      "Batch 'Legendary Flex Fit Hat': Generated 2 SKUs\n",
      "Batch 'Bandit Truck Trucker Hat': Generated 1 SKUs\n",
      "Batch 'Legendary Polo': Generated 24 SKUs\n",
      "Batch 'Leather Air Freshener': Generated 6 SKUs\n",
      "Batch 'Legendary Hoody': Generated 12 SKUs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_batch_dict(data=list,debug=False):\n",
    "    \"\"\"\n",
    "    Generate a dictionary capturing all generated SKU permutations for each batch.\n",
    "    Parameters:\n",
    "    - data: list of batch names (product models)\n",
    "    - debug: boolean flag to enable debug printing\n",
    "    Returns:\n",
    "    - batch_dict: dictionary where keys are batch names and values are lists of permutation dictionaries\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_dict = {} #capture updated batch data with SKUs\n",
    "\n",
    "    for batch_name in data:\n",
    "        # Get the row from Product_Catalog that matches this batch_name\n",
    "        batch_row = tables['Product_Catalog'][tables['Product_Catalog']['Name'] == batch_name].iloc[0]\n",
    "        \n",
    "        # Generate permutations for this batch (returns list of dictionaries)\n",
    "        permed_batch = generate_permutations(batch_row)\n",
    "        batch_dict[batch_name] = permed_batch\n",
    "        \n",
    "        # Add SKU to each permutation dictionary\n",
    "        for perm in permed_batch:\n",
    "            model, sku = generate_sku(perm)\n",
    "            perm['SKU'] = sku  # Add SKU key directly to the permutation dictionary\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"Batch '{batch_name}': Generated {len(permed_batch)} SKUs\")\n",
    "\n",
    "    return batch_dict\n",
    "\n",
    "batch_dict = generate_batch_dict(batch_name_list,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335985a7",
   "metadata": {},
   "source": [
    "Parse a given batch (collection of permutations with skus) into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05086e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_to_dataframe(batch_name='',data_source=dict, batch_name_list=batch_name_list,debug=False):\n",
    "    \"\"\"\n",
    "    Convert a batch's list of permutation dictionaries to a Pandas DataFrame.\n",
    "    Parameters:\n",
    "    - batch_name: String name of the batch to convert\n",
    "    - data_source: Dictionary of batches\n",
    "    - batch_name_list: List of valid batch names (default: batch_name_list)\n",
    "    - debug: Boolean flag to enable debug printing\n",
    "    Returns:\n",
    "    - batch_df: Pandas DataFrame for the specified batch\n",
    "    \"\"\"\n",
    "    for batch in data_source:\n",
    "        if batch == batch_name:\n",
    "            batch_df = pd.DataFrame(data_source[batch])\n",
    "            batch_df.name = f\"{batch_name}_df\"\n",
    "        # check for duplicate SKUs in the dataframe\n",
    "            duplicate_skus = batch_df['SKU'][batch_df['SKU'].duplicated()]\n",
    "            if not duplicate_skus.empty:\n",
    "                print(f\"WARNING: Found {len(duplicate_skus)} duplicate SKU(s) in batch '{batch_name}':\")\n",
    "                for sku in duplicate_skus.unique():\n",
    "                    duplicate_rows = batch_df[batch_df['SKU'] == sku]\n",
    "                    row_indices = duplicate_rows.index.tolist()\n",
    "                    print(f\"  SKU: {sku} at rows {row_indices}\")\n",
    "            else:\n",
    "                print(f\"No duplicate SKUs found in batch '{batch_name}'. Total SKUs: {len(batch_df)}\\n\")\n",
    "\n",
    "            if debug:\n",
    "                print(f\"Converted batch '{batch_name}' to DataFrame\\n name: {batch_name}_df\\n Shape: {batch_df.shape}\")\n",
    "    return batch_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e1d946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate SKUs found in batch 'Collectible Gold Keychain'. Total SKUs: 2\n",
      "\n",
      "Converted batch 'Collectible Gold Keychain' to DataFrame\n",
      " name: Collectible Gold Keychain_df\n",
      " Shape: (2, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Main_Category</th>\n",
       "      <th>Sub_Category</th>\n",
       "      <th>Size</th>\n",
       "      <th>Color</th>\n",
       "      <th>Material</th>\n",
       "      <th>Design</th>\n",
       "      <th>Name</th>\n",
       "      <th>SKU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Accessories, ACC, 4]</td>\n",
       "      <td>[Keychain, KYC, 11]</td>\n",
       "      <td>[, , ]</td>\n",
       "      <td>[Gold, GLD, 11]</td>\n",
       "      <td>[Metal, MTL, 5]</td>\n",
       "      <td>[Legendary Icon, LGI, 2]</td>\n",
       "      <td>Collectible Gold Keychain</td>\n",
       "      <td>ACCKYC11--GLD-MTL-LGI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Accessories, ACC, 4]</td>\n",
       "      <td>[Keychain, KYC, 11]</td>\n",
       "      <td>[, , ]</td>\n",
       "      <td>[Gold, GLD, 11]</td>\n",
       "      <td>[Metal, MTL, 5]</td>\n",
       "      <td>[Bandit Truck Icon, BTI, 4]</td>\n",
       "      <td>Collectible Gold Keychain</td>\n",
       "      <td>ACCKYC11--GLD-MTL-BTI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Main_Category         Sub_Category    Size            Color  \\\n",
       "0  [Accessories, ACC, 4]  [Keychain, KYC, 11]  [, , ]  [Gold, GLD, 11]   \n",
       "1  [Accessories, ACC, 4]  [Keychain, KYC, 11]  [, , ]  [Gold, GLD, 11]   \n",
       "\n",
       "          Material                       Design                       Name  \\\n",
       "0  [Metal, MTL, 5]     [Legendary Icon, LGI, 2]  Collectible Gold Keychain   \n",
       "1  [Metal, MTL, 5]  [Bandit Truck Icon, BTI, 4]  Collectible Gold Keychain   \n",
       "\n",
       "                     SKU  \n",
       "0  ACCKYC11--GLD-MTL-LGI  \n",
       "1  ACCKYC11--GLD-MTL-BTI  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_name = batch_name_list[0]\n",
    "batch_to_dataframe(batch_name,batch_dict,debug=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f68fcc",
   "metadata": {},
   "source": [
    "## Output dataframe to a CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c278ad7",
   "metadata": {},
   "source": [
    "Initialize an output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92f0bfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: Attempting to create file at: Results/Bandit Truck Logo Tee_skus_20251201.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: True\n",
      "Debug: Overwrite mode: True\n",
      "Overwriting existing CSV at: Results/Bandit Truck Logo Tee_skus_20251201.csv\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Bandit Truck Logo Tee_skus_20251201.csv\n",
      "\n",
      "Returned: Results/Bandit Truck Logo Tee_skus_20251201.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def initialize_output_csv(output_dir='', batch_name='', overwrite=False, debug=False):\n",
    "    \"\"\"\n",
    "    Initialize a CSV file for SKU batch output using a predefined template structure.\n",
    "    \n",
    "    Creates a timestamped CSV file with columns matching the sku_batch_template.csv format.\n",
    "    The filename includes the batch name and date for organization and tracking.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    output_dir : str\n",
    "        Directory path where the CSV should be created (e.g., 'Results/').\n",
    "        Directory will be created if it doesn't exist.\n",
    "    batch_name : str\n",
    "        Name of the product model/batch being processed. Used in the filename\n",
    "        for identification (e.g., 'Basic Tee' -> 'Basic Tee_skus_20251121.csv').\n",
    "    overwrite : bool, optional\n",
    "        Controls behavior when file already exists:\n",
    "        - False (default): Skips file creation and returns None\n",
    "        - True: Replaces existing file with new empty template\n",
    "    debug : bool, optional\n",
    "        If True, prints detailed diagnostic information including file paths,\n",
    "        directory status, and overwrite mode. Default is False.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str or None\n",
    "        Absolute path to the created CSV file if successful, or None if file\n",
    "        already exists and overwrite=False.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - File naming format: '{batch_name}_skus_{YYYYMMDD}.csv'\n",
    "    - Date-based naming allows multiple generations per batch on different days\n",
    "    - Template loaded from 'CHARTS/sku_batch_template.csv'\n",
    "    - All SKU columns from template are preserved in the output file\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    Create new batch file:\n",
    "    >>> path = initialize_output_csv('Results/', 'Basic Tee', overwrite=False)\n",
    "    >>> print(path)\n",
    "    'Results/Basic Tee_skus_20251121.csv'\n",
    "    \n",
    "    Overwrite existing batch file:\n",
    "    >>> path = initialize_output_csv('Results/', 'Basic Tee', overwrite=True)\n",
    "    Overwriting existing CSV at: Results/Basic Tee_skus_20251121.csv\n",
    "    \n",
    "    Debug mode for troubleshooting:\n",
    "    >>> path = initialize_output_csv('Results/', 'Basic Tee', debug=True)\n",
    "    Debug: Attempting to create file at: Results/Basic Tee_skus_20251121.csv\n",
    "    Debug: Directory exists: True\n",
    "    Debug: File exists: False\n",
    "    Debug: Overwrite mode: False\n",
    "    \"\"\"\n",
    "\n",
    "    # timestamp the file creation in the filepath\n",
    "    timestamp = datetime.now().strftime('%Y%m%d')\n",
    "\n",
    "    file_path = output_dir + batch_name + '_skus_' + timestamp + '.csv'\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Debug: Attempting to create file at: {file_path}\")\n",
    "        print(f\"Debug: Directory exists: {os.path.exists(output_dir)}\")\n",
    "        print(f\"Debug: File exists: {os.path.exists(file_path)}\")\n",
    "        print(f\"Debug: Overwrite mode: {overwrite}\")\n",
    "\n",
    "    # Check if FILE already exists (not directory)\n",
    "    if os.path.exists(file_path):\n",
    "        if not overwrite:\n",
    "            print(f\"CSV already exists at: {file_path}\")\n",
    "            print(f\"Set overwrite=True to replace existing file\")\n",
    "            return None\n",
    "        else:\n",
    "            print(f\"Overwriting existing CSV at: {file_path}\")\n",
    "    \n",
    "    # Load the template CSV from CHARTS directory\n",
    "    template_path = 'CHARTS/sku_batch_template.csv'\n",
    "    template_df = pd.read_csv(template_path)\n",
    "    template_columns = template_df.columns.tolist()\n",
    "    \n",
    "    # Create an empty DataFrame with these columns\n",
    "    output_df = pd.DataFrame(columns=template_columns)\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_df.to_csv(file_path, index=False)\n",
    "    \n",
    "    print(f\"Created new CSV template with columns: {template_columns}\")\n",
    "    print(f\"Saved to: {file_path}\")\n",
    "    \n",
    "    return file_path\n",
    "\n",
    "# Test the function\n",
    "output_dir = 'Results/'\n",
    "file_path = initialize_output_csv(output_dir, model, overwrite=True, debug=True)\n",
    "print(f\"\\nReturned: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dc8b6c",
   "metadata": {},
   "source": [
    "Populate the output with a given dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc8ed778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate SKUs found in batch 'Legendary Distressed Hat'. Total SKUs: 2\n",
      "\n",
      "Populating CSV at: Results/Bandit Truck Logo Tee_skus_20251201.csv with DataFrame of shape: (2, 8)\n",
      "Successfully populated CSV at: Results/Bandit Truck Logo Tee_skus_20251201.csv\n",
      "Verification: File contains 2 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Results/Bandit Truck Logo Tee_skus_20251201.csv'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def populate_output_csv(file_path='', df=pd.DataFrame(), debug=False):\n",
    "    \"\"\"\n",
    "    Populate the output CSV file with SKU data from the provided DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "        Path to the CSV file to populate.\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing SKU data to write to the CSV.\n",
    "    debug : bool, optional\n",
    "        If True, prints detailed diagnostic information. Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str or None\n",
    "        Returns the file path if the CSV was populated successfully, or None if there was an error or the file is empty.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Appends the DataFrame to the specified CSV file.\n",
    "    - If the file does not exist, writes the header; otherwise, appends without header.\n",
    "    - Verifies that the file was populated by reading it back and checking for rows.\n",
    "    - Prints warnings or errors if the file is missing or empty, or if verification fails.\n",
    "    \"\"\"\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Populating CSV at: {file_path} with DataFrame of shape: {df.shape}\")\n",
    "    \n",
    "    # Write the DataFrame to the CSV, appending if file exists\n",
    "    df.to_csv(file_path, mode='a', index=False, header=not os.path.exists(file_path))\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Successfully populated CSV at: {file_path}\")    \n",
    "\n",
    "    # Verify if file was populated successfully\n",
    "    try:\n",
    "        # Check if file exists and has content\n",
    "        if os.path.exists(file_path):\n",
    "            # Read the file to verify it has data\n",
    "            verification_df = pd.read_csv(file_path)\n",
    "            \n",
    "            if len(verification_df) > 0:\n",
    "                if debug:\n",
    "                    print(f\"Verification: File contains {len(verification_df)} rows\")\n",
    "                return file_path\n",
    "            else:\n",
    "                print(f\"WARNING: File exists but is empty: {file_path}\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"WARNING: File does not exist: {file_path}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to verify file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test the function\n",
    "test_batch_name = batch_name_list[0]\n",
    "test_batch_df = batch_to_dataframe(test_batch_name, batch_dict)\n",
    "populate_output_csv(file_path, test_batch_df, debug=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f457b7a",
   "metadata": {},
   "source": [
    "Factor above functions as helpers into a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc6b0c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate SKUs found in batch 'Legendary Distressed Hat'. Total SKUs: 2\n",
      "\n",
      "Debug: Attempting to create file at: Results/Legendary Distressed Hat_skus_20251201.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: False\n",
      "Debug: Overwrite mode: True\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Legendary Distressed Hat_skus_20251201.csv\n",
      "Populating CSV at: Results/Legendary Distressed Hat_skus_20251201.csv with DataFrame of shape: (2, 8)\n",
      "Successfully populated CSV at: Results/Legendary Distressed Hat_skus_20251201.csv\n",
      "Verification: File contains 2 rows\n",
      "Successfully generated and populated CSV at: Results/Legendary Distressed Hat_skus_20251201.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Results/Legendary Distressed Hat_skus_20251201.csv'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_output_csv(output_dir='', batch_name='', df=pd.DataFrame(), overwrite=False, debug=False):\n",
    "    \"\"\"\n",
    "    Generate and populate an output CSV file for a given batch DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    output_dir : str\n",
    "        Directory path where the CSV should be created (e.g., 'Results/').\n",
    "    batch_name : str\n",
    "        Name of the product model/batch being processed.\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing SKU data to write to the CSV.\n",
    "    overwrite : bool, optional\n",
    "        If True, overwrites existing file; if False, skips if file exists. Default is False.\n",
    "    debug : bool, optional\n",
    "        If True, prints detailed diagnostic information. Default is False.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str or None\n",
    "        Absolute path to the created and populated CSV file if successful, or None on failure.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the output CSV\n",
    "    file_path = initialize_output_csv(output_dir, batch_name, overwrite, debug)\n",
    "    \n",
    "    if file_path is None:\n",
    "        if debug:\n",
    "            print(f\"Skipping population: File already exists and overwrite=False\")\n",
    "        return None\n",
    "    \n",
    "    # Populate the CSV with the provided DataFrame\n",
    "    populated_path = populate_output_csv(file_path, df, debug)\n",
    "    \n",
    "    if populated_path is not None:\n",
    "        if debug:\n",
    "            print(f\"Successfully generated and populated CSV at: {populated_path}\")\n",
    "        return populated_path\n",
    "    else:\n",
    "        if debug:\n",
    "            print(f\"Failed to populate CSV at: {file_path}\")\n",
    "        return None\n",
    "    \n",
    "# Test the function\n",
    "test_batch_name = batch_name_list[0]\n",
    "test_batch_df = batch_to_dataframe(test_batch_name, batch_dict)\n",
    "generate_output_csv('Results/', test_batch_name, test_batch_df, overwrite=True, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecb7e6a",
   "metadata": {},
   "source": [
    "## SKU number capture test\n",
    "\n",
    "run the above functions to generate SKUs and write them into the initialized csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99869a93",
   "metadata": {},
   "source": [
    "### Scripting the Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bc9892d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet names and catalog features MATCH exactly!\n",
      "All product names are unique, total batches to process: 18\n",
      "No duplicate SKUs found in batch 'Legendary Distressed Hat'. Total SKUs: 2\n",
      "\n",
      "No duplicate SKUs found in batch 'Bandit Banquet Tee'. Total SKUs: 12\n",
      "\n",
      "No duplicate SKUs found in batch 'Bandit Truck Wreath Tee'. Total SKUs: 12\n",
      "\n",
      "No duplicate SKUs found in batch 'Bandit Truck Jacket'. Total SKUs: 12\n",
      "\n",
      "No duplicate SKUs found in batch 'Bandit Truck Flex Fit Hat'. Total SKUs: 2\n",
      "\n",
      "No duplicate SKUs found in batch 'Legendary Trucker Hat'. Total SKUs: 2\n",
      "\n",
      "No duplicate SKUs found in batch 'Collectible Gold Keychain'. Total SKUs: 2\n",
      "\n",
      "No duplicate SKUs found in batch 'Legendary Long Sleeve Tee'. Total SKUs: 12\n",
      "\n",
      "No duplicate SKUs found in batch 'Legendary Jacket'. Total SKUs: 12\n",
      "\n",
      "No duplicate SKUs found in batch 'Legendary Tee'. Total SKUs: 48\n",
      "\n",
      "No duplicate SKUs found in batch 'Bandit Truck Logo Tee'. Total SKUs: 12\n",
      "\n",
      "No duplicate SKUs found in batch 'Legendary Sweater'. Total SKUs: 12\n",
      "\n",
      "No duplicate SKUs found in batch 'Bandit Truck Wreath Sweater'. Total SKUs: 12\n",
      "\n",
      "No duplicate SKUs found in batch 'Legendary Flex Fit Hat'. Total SKUs: 2\n",
      "\n",
      "No duplicate SKUs found in batch 'Bandit Truck Trucker Hat'. Total SKUs: 1\n",
      "\n",
      "No duplicate SKUs found in batch 'Legendary Polo'. Total SKUs: 24\n",
      "\n",
      "No duplicate SKUs found in batch 'Leather Air Freshener'. Total SKUs: 6\n",
      "\n",
      "No duplicate SKUs found in batch 'Legendary Hoody'. Total SKUs: 12\n",
      "\n",
      "Debug: Attempting to create file at: Results/Legendary Distressed Hat_skus_20251201.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: True\n",
      "Debug: Overwrite mode: True\n",
      "Overwriting existing CSV at: Results/Legendary Distressed Hat_skus_20251201.csv\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Legendary Distressed Hat_skus_20251201.csv\n",
      "Populating CSV at: Results/Legendary Distressed Hat_skus_20251201.csv with DataFrame of shape: (2, 8)\n",
      "Successfully populated CSV at: Results/Legendary Distressed Hat_skus_20251201.csv\n",
      "Verification: File contains 2 rows\n",
      "Successfully generated and populated CSV at: Results/Legendary Distressed Hat_skus_20251201.csv\n",
      "DataFrame Name: Legendary Distressed Hat_df, Shape: (2, 8)\n",
      "Debug: Attempting to create file at: Results/Bandit Banquet Tee_skus_20251201.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: False\n",
      "Debug: Overwrite mode: True\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Bandit Banquet Tee_skus_20251201.csv\n",
      "Populating CSV at: Results/Bandit Banquet Tee_skus_20251201.csv with DataFrame of shape: (12, 9)\n",
      "Successfully populated CSV at: Results/Bandit Banquet Tee_skus_20251201.csv\n",
      "Verification: File contains 12 rows\n",
      "Successfully generated and populated CSV at: Results/Bandit Banquet Tee_skus_20251201.csv\n",
      "DataFrame Name: Bandit Banquet Tee_df, Shape: (12, 9)\n",
      "Debug: Attempting to create file at: Results/Bandit Truck Wreath Tee_skus_20251201.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: False\n",
      "Debug: Overwrite mode: True\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Bandit Truck Wreath Tee_skus_20251201.csv\n",
      "Populating CSV at: Results/Bandit Truck Wreath Tee_skus_20251201.csv with DataFrame of shape: (12, 9)\n",
      "Successfully populated CSV at: Results/Bandit Truck Wreath Tee_skus_20251201.csv\n",
      "Verification: File contains 12 rows\n",
      "Successfully generated and populated CSV at: Results/Bandit Truck Wreath Tee_skus_20251201.csv\n",
      "DataFrame Name: Bandit Truck Wreath Tee_df, Shape: (12, 9)\n",
      "Debug: Attempting to create file at: Results/Bandit Truck Jacket_skus_20251201.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: False\n",
      "Debug: Overwrite mode: True\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Bandit Truck Jacket_skus_20251201.csv\n",
      "Populating CSV at: Results/Bandit Truck Jacket_skus_20251201.csv with DataFrame of shape: (12, 9)\n",
      "Successfully populated CSV at: Results/Bandit Truck Jacket_skus_20251201.csv\n",
      "Verification: File contains 12 rows\n",
      "Successfully generated and populated CSV at: Results/Bandit Truck Jacket_skus_20251201.csv\n",
      "DataFrame Name: Bandit Truck Jacket_df, Shape: (12, 9)\n",
      "Debug: Attempting to create file at: Results/Bandit Truck Flex Fit Hat_skus_20251201.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: False\n",
      "Debug: Overwrite mode: True\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Bandit Truck Flex Fit Hat_skus_20251201.csv\n",
      "Populating CSV at: Results/Bandit Truck Flex Fit Hat_skus_20251201.csv with DataFrame of shape: (2, 9)\n",
      "Successfully populated CSV at: Results/Bandit Truck Flex Fit Hat_skus_20251201.csv\n",
      "Verification: File contains 2 rows\n",
      "Successfully generated and populated CSV at: Results/Bandit Truck Flex Fit Hat_skus_20251201.csv\n",
      "DataFrame Name: Bandit Truck Flex Fit Hat_df, Shape: (2, 9)\n",
      "Debug: Attempting to create file at: Results/Legendary Trucker Hat_skus_20251201.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: False\n",
      "Debug: Overwrite mode: True\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Legendary Trucker Hat_skus_20251201.csv\n",
      "Populating CSV at: Results/Legendary Trucker Hat_skus_20251201.csv with DataFrame of shape: (2, 8)\n",
      "Successfully populated CSV at: Results/Legendary Trucker Hat_skus_20251201.csv\n",
      "Verification: File contains 2 rows\n",
      "Successfully generated and populated CSV at: Results/Legendary Trucker Hat_skus_20251201.csv\n",
      "DataFrame Name: Legendary Trucker Hat_df, Shape: (2, 8)\n",
      "Debug: Attempting to create file at: Results/Collectible Gold Keychain_skus_20251201.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: False\n",
      "Debug: Overwrite mode: True\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Collectible Gold Keychain_skus_20251201.csv\n",
      "Populating CSV at: Results/Collectible Gold Keychain_skus_20251201.csv with DataFrame of shape: (2, 7)\n",
      "Successfully populated CSV at: Results/Collectible Gold Keychain_skus_20251201.csv\n",
      "Verification: File contains 2 rows\n",
      "Successfully generated and populated CSV at: Results/Collectible Gold Keychain_skus_20251201.csv\n",
      "DataFrame Name: Collectible Gold Keychain_df, Shape: (2, 7)\n",
      "Debug: Attempting to create file at: Results/Legendary Long Sleeve Tee_skus_20251201.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: False\n",
      "Debug: Overwrite mode: True\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Legendary Long Sleeve Tee_skus_20251201.csv\n",
      "Populating CSV at: Results/Legendary Long Sleeve Tee_skus_20251201.csv with DataFrame of shape: (12, 9)\n",
      "Successfully populated CSV at: Results/Legendary Long Sleeve Tee_skus_20251201.csv\n",
      "Verification: File contains 12 rows\n",
      "Successfully generated and populated CSV at: Results/Legendary Long Sleeve Tee_skus_20251201.csv\n",
      "DataFrame Name: Legendary Long Sleeve Tee_df, Shape: (12, 9)\n",
      "Debug: Attempting to create file at: Results/Legendary Jacket_skus_20251201.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: False\n",
      "Debug: Overwrite mode: True\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Legendary Jacket_skus_20251201.csv\n",
      "Populating CSV at: Results/Legendary Jacket_skus_20251201.csv with DataFrame of shape: (12, 9)\n",
      "Successfully populated CSV at: Results/Legendary Jacket_skus_20251201.csv\n",
      "Verification: File contains 12 rows\n",
      "Successfully generated and populated CSV at: Results/Legendary Jacket_skus_20251201.csv\n",
      "DataFrame Name: Legendary Jacket_df, Shape: (12, 9)\n",
      "Debug: Attempting to create file at: Results/Legendary Tee_skus_20251201.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: False\n",
      "Debug: Overwrite mode: True\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Legendary Tee_skus_20251201.csv\n",
      "Populating CSV at: Results/Legendary Tee_skus_20251201.csv with DataFrame of shape: (48, 9)\n",
      "Successfully populated CSV at: Results/Legendary Tee_skus_20251201.csv\n",
      "Verification: File contains 48 rows\n",
      "Successfully generated and populated CSV at: Results/Legendary Tee_skus_20251201.csv\n",
      "DataFrame Name: Legendary Tee_df, Shape: (48, 9)\n",
      "Debug: Attempting to create file at: Results/Bandit Truck Logo Tee_skus_20251201.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: True\n",
      "Debug: Overwrite mode: True\n",
      "Overwriting existing CSV at: Results/Bandit Truck Logo Tee_skus_20251201.csv\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Bandit Truck Logo Tee_skus_20251201.csv\n",
      "Populating CSV at: Results/Bandit Truck Logo Tee_skus_20251201.csv with DataFrame of shape: (12, 9)\n",
      "Successfully populated CSV at: Results/Bandit Truck Logo Tee_skus_20251201.csv\n",
      "Verification: File contains 12 rows\n",
      "Successfully generated and populated CSV at: Results/Bandit Truck Logo Tee_skus_20251201.csv\n",
      "DataFrame Name: Bandit Truck Logo Tee_df, Shape: (12, 9)\n",
      "Debug: Attempting to create file at: Results/Legendary Sweater_skus_20251201.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: False\n",
      "Debug: Overwrite mode: True\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Legendary Sweater_skus_20251201.csv\n",
      "Populating CSV at: Results/Legendary Sweater_skus_20251201.csv with DataFrame of shape: (12, 9)\n",
      "Successfully populated CSV at: Results/Legendary Sweater_skus_20251201.csv\n",
      "Verification: File contains 12 rows\n",
      "Successfully generated and populated CSV at: Results/Legendary Sweater_skus_20251201.csv\n",
      "DataFrame Name: Legendary Sweater_df, Shape: (12, 9)\n",
      "Debug: Attempting to create file at: Results/Bandit Truck Wreath Sweater_skus_20251201.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: False\n",
      "Debug: Overwrite mode: True\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Bandit Truck Wreath Sweater_skus_20251201.csv\n",
      "Populating CSV at: Results/Bandit Truck Wreath Sweater_skus_20251201.csv with DataFrame of shape: (12, 9)\n",
      "Successfully populated CSV at: Results/Bandit Truck Wreath Sweater_skus_20251201.csv\n",
      "Verification: File contains 12 rows\n",
      "Successfully generated and populated CSV at: Results/Bandit Truck Wreath Sweater_skus_20251201.csv\n",
      "DataFrame Name: Bandit Truck Wreath Sweater_df, Shape: (12, 9)\n",
      "Debug: Attempting to create file at: Results/Legendary Flex Fit Hat_skus_20251201.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: False\n",
      "Debug: Overwrite mode: True\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Legendary Flex Fit Hat_skus_20251201.csv\n",
      "Populating CSV at: Results/Legendary Flex Fit Hat_skus_20251201.csv with DataFrame of shape: (2, 9)\n",
      "Successfully populated CSV at: Results/Legendary Flex Fit Hat_skus_20251201.csv\n",
      "Verification: File contains 2 rows\n",
      "Successfully generated and populated CSV at: Results/Legendary Flex Fit Hat_skus_20251201.csv\n",
      "DataFrame Name: Legendary Flex Fit Hat_df, Shape: (2, 9)\n",
      "Debug: Attempting to create file at: Results/Bandit Truck Trucker Hat_skus_20251201.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: False\n",
      "Debug: Overwrite mode: True\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Bandit Truck Trucker Hat_skus_20251201.csv\n",
      "Populating CSV at: Results/Bandit Truck Trucker Hat_skus_20251201.csv with DataFrame of shape: (1, 8)\n",
      "Successfully populated CSV at: Results/Bandit Truck Trucker Hat_skus_20251201.csv\n",
      "Verification: File contains 1 rows\n",
      "Successfully generated and populated CSV at: Results/Bandit Truck Trucker Hat_skus_20251201.csv\n",
      "DataFrame Name: Bandit Truck Trucker Hat_df, Shape: (1, 8)\n",
      "Debug: Attempting to create file at: Results/Legendary Polo_skus_20251201.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: False\n",
      "Debug: Overwrite mode: True\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Legendary Polo_skus_20251201.csv\n",
      "Populating CSV at: Results/Legendary Polo_skus_20251201.csv with DataFrame of shape: (24, 9)\n",
      "Successfully populated CSV at: Results/Legendary Polo_skus_20251201.csv\n",
      "Verification: File contains 24 rows\n",
      "Successfully generated and populated CSV at: Results/Legendary Polo_skus_20251201.csv\n",
      "DataFrame Name: Legendary Polo_df, Shape: (24, 9)\n",
      "Debug: Attempting to create file at: Results/Leather Air Freshener_skus_20251201.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: False\n",
      "Debug: Overwrite mode: True\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Leather Air Freshener_skus_20251201.csv\n",
      "Populating CSV at: Results/Leather Air Freshener_skus_20251201.csv with DataFrame of shape: (6, 8)\n",
      "Successfully populated CSV at: Results/Leather Air Freshener_skus_20251201.csv\n",
      "Verification: File contains 6 rows\n",
      "Successfully generated and populated CSV at: Results/Leather Air Freshener_skus_20251201.csv\n",
      "DataFrame Name: Leather Air Freshener_df, Shape: (6, 8)\n",
      "Debug: Attempting to create file at: Results/Legendary Hoody_skus_20251201.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: False\n",
      "Debug: Overwrite mode: True\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Legendary Hoody_skus_20251201.csv\n",
      "Populating CSV at: Results/Legendary Hoody_skus_20251201.csv with DataFrame of shape: (12, 9)\n",
      "Successfully populated CSV at: Results/Legendary Hoody_skus_20251201.csv\n",
      "Verification: File contains 12 rows\n",
      "Successfully generated and populated CSV at: Results/Legendary Hoody_skus_20251201.csv\n",
      "DataFrame Name: Legendary Hoody_df, Shape: (12, 9)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "catalog_data_source = \"CHARTS/catalog.numbers\"\n",
    "tables = load_catalog_data(catalog_data_source)\n",
    "\n",
    "# Validate and extract feature lists\n",
    "code_sheet_list, catalog_feature_list = validate_catalog_features(tables)\n",
    "\n",
    "# Prepare batch names\n",
    "product_models_data_source = tables['Product_Catalog']\n",
    "batch_name_list = prepare_batches(product_models_data_source) \n",
    "\n",
    "# Generate batch dictionary\n",
    "batch_dict = generate_batch_dict(batch_name_list)\n",
    "\n",
    "# Parse batches into dataframes\n",
    "batch_df_list = []\n",
    "for batch in batch_dict:\n",
    "    batch_df = batch_to_dataframe(batch,batch_dict)\n",
    "    batch_df_list.append(batch_df)\n",
    "\n",
    "# output batches to CSV files\n",
    "for df in batch_df_list:\n",
    "    generate_output_csv(output_dir='Results/', batch_name=df.name.replace('_df',''), df=df, overwrite=True, debug=True)\n",
    "    print(f\"DataFrame Name: {df.name}, Shape: {df.shape}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af0d4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "096b1070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: Attempting to create file at: Results/Legendary Long Sleeve Tee_skus_20251121.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: True\n",
      "Debug: Overwrite mode: True\n",
      "Overwriting existing CSV at: Results/Legendary Long Sleeve Tee_skus_20251121.csv\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Legendary Long Sleeve Tee_skus_20251121.csv\n",
      "DataFrame Name: Legendary Long Sleeve Tee_df, Shape: (8, 9)\n",
      "Debug: Attempting to create file at: Results/Bandit Truck Logo Tee_skus_20251121.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: True\n",
      "Debug: Overwrite mode: True\n",
      "Overwriting existing CSV at: Results/Bandit Truck Logo Tee_skus_20251121.csv\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Bandit Truck Logo Tee_skus_20251121.csv\n",
      "DataFrame Name: Bandit Truck Logo Tee_df, Shape: (8, 9)\n",
      "Debug: Attempting to create file at: Results/Legendary Sweater_skus_20251121.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: True\n",
      "Debug: Overwrite mode: True\n",
      "Overwriting existing CSV at: Results/Legendary Sweater_skus_20251121.csv\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Legendary Sweater_skus_20251121.csv\n",
      "DataFrame Name: Legendary Sweater_df, Shape: (8, 9)\n",
      "Debug: Attempting to create file at: Results/Legendary Tee_skus_20251121.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: True\n",
      "Debug: Overwrite mode: True\n",
      "Overwriting existing CSV at: Results/Legendary Tee_skus_20251121.csv\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Legendary Tee_skus_20251121.csv\n",
      "DataFrame Name: Legendary Tee_df, Shape: (32, 9)\n",
      "Debug: Attempting to create file at: Results/Legendary Distressed Hat_skus_20251121.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: True\n",
      "Debug: Overwrite mode: True\n",
      "Overwriting existing CSV at: Results/Legendary Distressed Hat_skus_20251121.csv\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Legendary Distressed Hat_skus_20251121.csv\n",
      "DataFrame Name: Legendary Distressed Hat_df, Shape: (2, 8)\n",
      "Debug: Attempting to create file at: Results/Bandit Banquet Tee_skus_20251121.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: True\n",
      "Debug: Overwrite mode: True\n",
      "Overwriting existing CSV at: Results/Bandit Banquet Tee_skus_20251121.csv\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Bandit Banquet Tee_skus_20251121.csv\n",
      "DataFrame Name: Bandit Banquet Tee_df, Shape: (8, 9)\n",
      "Debug: Attempting to create file at: Results/Bandit Truck Wreath Tee_skus_20251121.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: True\n",
      "Debug: Overwrite mode: True\n",
      "Overwriting existing CSV at: Results/Bandit Truck Wreath Tee_skus_20251121.csv\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Bandit Truck Wreath Tee_skus_20251121.csv\n",
      "DataFrame Name: Bandit Truck Wreath Tee_df, Shape: (8, 9)\n",
      "Debug: Attempting to create file at: Results/Legendary Hoody_skus_20251121.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: True\n",
      "Debug: Overwrite mode: True\n",
      "Overwriting existing CSV at: Results/Legendary Hoody_skus_20251121.csv\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Legendary Hoody_skus_20251121.csv\n",
      "DataFrame Name: Legendary Hoody_df, Shape: (8, 9)\n",
      "Debug: Attempting to create file at: Results/Bandit Truck Flex Fit Hat_skus_20251121.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: True\n",
      "Debug: Overwrite mode: True\n",
      "Overwriting existing CSV at: Results/Bandit Truck Flex Fit Hat_skus_20251121.csv\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Bandit Truck Flex Fit Hat_skus_20251121.csv\n",
      "DataFrame Name: Bandit Truck Flex Fit Hat_df, Shape: (2, 9)\n",
      "Debug: Attempting to create file at: Results/Legendary Jacket_skus_20251121.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: True\n",
      "Debug: Overwrite mode: True\n",
      "Overwriting existing CSV at: Results/Legendary Jacket_skus_20251121.csv\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Legendary Jacket_skus_20251121.csv\n",
      "DataFrame Name: Legendary Jacket_df, Shape: (8, 9)\n",
      "Debug: Attempting to create file at: Results/Leather Air Freshener_skus_20251121.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: True\n",
      "Debug: Overwrite mode: True\n",
      "Overwriting existing CSV at: Results/Leather Air Freshener_skus_20251121.csv\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Leather Air Freshener_skus_20251121.csv\n",
      "DataFrame Name: Leather Air Freshener_df, Shape: (6, 8)\n",
      "Debug: Attempting to create file at: Results/Legendary Flex Fit Hat_skus_20251121.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: True\n",
      "Debug: Overwrite mode: True\n",
      "Overwriting existing CSV at: Results/Legendary Flex Fit Hat_skus_20251121.csv\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Legendary Flex Fit Hat_skus_20251121.csv\n",
      "DataFrame Name: Legendary Flex Fit Hat_df, Shape: (2, 9)\n",
      "Debug: Attempting to create file at: Results/Bandit Truck Wreath Sweater_skus_20251121.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: True\n",
      "Debug: Overwrite mode: True\n",
      "Overwriting existing CSV at: Results/Bandit Truck Wreath Sweater_skus_20251121.csv\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Bandit Truck Wreath Sweater_skus_20251121.csv\n",
      "DataFrame Name: Bandit Truck Wreath Sweater_df, Shape: (8, 9)\n",
      "Debug: Attempting to create file at: Results/Legendary Polo_skus_20251121.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: True\n",
      "Debug: Overwrite mode: True\n",
      "Overwriting existing CSV at: Results/Legendary Polo_skus_20251121.csv\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Legendary Polo_skus_20251121.csv\n",
      "DataFrame Name: Legendary Polo_df, Shape: (16, 9)\n",
      "Debug: Attempting to create file at: Results/Bandit Truck Trucker Hat_skus_20251121.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: True\n",
      "Debug: Overwrite mode: True\n",
      "Overwriting existing CSV at: Results/Bandit Truck Trucker Hat_skus_20251121.csv\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Bandit Truck Trucker Hat_skus_20251121.csv\n",
      "DataFrame Name: Bandit Truck Trucker Hat_df, Shape: (1, 8)\n",
      "Debug: Attempting to create file at: Results/Legendary Trucker Hat_skus_20251121.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: True\n",
      "Debug: Overwrite mode: True\n",
      "Overwriting existing CSV at: Results/Legendary Trucker Hat_skus_20251121.csv\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Legendary Trucker Hat_skus_20251121.csv\n",
      "DataFrame Name: Legendary Trucker Hat_df, Shape: (2, 8)\n",
      "Debug: Attempting to create file at: Results/Bandit Truck Jacket_skus_20251121.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: True\n",
      "Debug: Overwrite mode: True\n",
      "Overwriting existing CSV at: Results/Bandit Truck Jacket_skus_20251121.csv\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Bandit Truck Jacket_skus_20251121.csv\n",
      "DataFrame Name: Bandit Truck Jacket_df, Shape: (8, 9)\n",
      "Debug: Attempting to create file at: Results/Collectible Gold Keychain_skus_20251121.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: True\n",
      "Debug: Overwrite mode: True\n",
      "Overwriting existing CSV at: Results/Collectible Gold Keychain_skus_20251121.csv\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Collectible Gold Keychain_skus_20251121.csv\n",
      "DataFrame Name: Collectible Gold Keychain_df, Shape: (2, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for df in batch_df_list:\n",
    "    initialize_output_csv(output_dir='Results/', batch_name=df.name.replace('_df',''), overwrite=True, debug=True)\n",
    "    print(f\"DataFrame Name: {df.name}, Shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9ad5a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04418dbf",
   "metadata": {},
   "source": [
    "### Write generated SKUS to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673174cc",
   "metadata": {},
   "source": [
    "Start with a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8db15d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
