{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb73f2f1",
   "metadata": {},
   "source": [
    "# Sku Generator Beta Testing Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4993eae4",
   "metadata": {},
   "source": [
    "Read Apple Numbers file with multiple sheets into Pandas Data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee285f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numbers_parser import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e357ae0d",
   "metadata": {},
   "source": [
    "## Data Preparation and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24a4466e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Product_Catalog:\n",
      "   Index Main Category           Sub Category                       Name  \\\n",
      "0    0.0         Shirt              Tee Shirt         Bandit Banquet Tee   \n",
      "1    1.0         Shirt              Tee Shirt    Bandit Truck Wreath Tee   \n",
      "2    2.0         Shirt              Tee Shirt      Bandit Truck Logo Tee   \n",
      "3    3.0         Shirt              Tee Shirt              Legendary Tee   \n",
      "4    4.0         Shirt  Long Sleeve Tee Shirt  Legendary Long Sleeve Tee   \n",
      "\n",
      "                       Size     Fit                     Color  \\\n",
      "0  S,M,L,XL,2XL,3XL,4XL,5XL  Unisex                    Yellow   \n",
      "1  S,M,L,XL,2XL,3XL,4XL,5XL  Unisex                     Black   \n",
      "2  S,M,L,XL,2XL,3XL,4XL,5XL  Unisex                     Black   \n",
      "3  S,M,L,XL,2XL,3XL,4XL,5XL  Unisex  White, Blue, Gray, Black   \n",
      "4  S,M,L,XL,2XL,3XL,4XL,5XL  Unisex                      Blue   \n",
      "\n",
      "                                    Design Material           Scent  \n",
      "0                           Bandit Banquet   Cotton  Not Applicable  \n",
      "1                        Bandit Truck Icon   Cotton  Not Applicable  \n",
      "2  Bandit Truck Icon;Bandit Truck Wordmark   Cotton  Not Applicable  \n",
      "3        Legendary Icon;Legendary Wordmark   Cotton  Not Applicable  \n",
      "4        Legendary Icon;Legendary Wordmark    Nylon  Not Applicable  \n",
      "\n",
      "Prefix_Codes:\n",
      "  Prefix         Feature     Comments\n",
      "0    NAN  Not Applicable         None\n",
      "1     MA   Main Category      Apparel\n",
      "2     MB   Main Category  Accessories\n",
      "3     MP   Main Category        Parts\n",
      "4     US    Sub Category       Shirts\n",
      "\n",
      "Main_Category:\n",
      "   Code Prefix            Name Comments\n",
      "0   0.0   MNAN  Not Applicable     None\n",
      "1   1.0     MA           Shirt     None\n",
      "2   2.0     MA       Outerwear     None\n",
      "3   3.0     MA        Headwear     None\n",
      "4   4.0     MB     Accessories     None\n",
      "\n",
      "Sub_Category:\n",
      "    Code Prefix                   Name Main Category Comments\n",
      "0    0.0   UNAN         Not Applicable          None     None\n",
      "1  101.0     US              Tee Shirt         Shirt     None\n",
      "2  102.0     US  Long Sleeve Tee Shirt         Shirt     None\n",
      "3  103.0     US                   Polo         Shirt     None\n",
      "4  201.0     UO                Sweater     Outerwear     None\n",
      "\n",
      "Size:\n",
      "   Code Prefix Abbreviation            Name           Comments\n",
      "0   0.0   SNAN           NA  Not Applicable  Non Apparel Items\n",
      "1   1.0     SZ           CS     Child Small               None\n",
      "2   2.0     SZ           CM    Child Medium               None\n",
      "3   3.0     SZ           CL     Child Large               None\n",
      "4   4.0     SZ           XS     Extra Small               None\n",
      "\n",
      "Fit:\n",
      "   Code Prefix            Name Comments\n",
      "0   0.0  FTNAN  Not Applicable     None\n",
      "1   1.0     FT          Unisex     None\n",
      "2   2.0     FT            Male     None\n",
      "3   3.0     FT          Female     None\n",
      "\n",
      "Color:\n",
      "   Code Prefix    Name Comments\n",
      "0   0.0  CLNAN      NA     None\n",
      "1   1.0     CL   White     None\n",
      "2   2.0     CL   Black     None\n",
      "3   3.0     CL    Gray     None\n",
      "4   4.0     CL  Yellow     None\n",
      "\n",
      "Design:\n",
      "   Code Prefix                Name Comments\n",
      "0   0.0   DNAN      Not Applicable     None\n",
      "1   1.0      D      Bandit Banquet     None\n",
      "2   2.0      D      Legendary Icon     None\n",
      "3   3.0      D  Legendary Wordmark     None\n",
      "4   4.0      D   Bandit Truck Icon     None\n",
      "\n",
      "Material:\n",
      "   Code  Prefix            Name Comments\n",
      "0   0.0  MATNAN  Not Applicable     None\n",
      "1   1.0     MAT          Cotton     None\n",
      "2   2.0     MAT           Nylon     None\n",
      "3   3.0     MAT           Blend     None\n",
      "4   4.0     MAT         Leather     None\n",
      "\n",
      "Scent:\n",
      "   Code Prefix              Name Comments\n",
      "0   0.0  STNAN    Not Applicable     None\n",
      "1   1.0     ST  Callahan Leather     None\n",
      "2   2.0     ST   Vanilla Leather     None\n",
      "3   3.0     ST    Cowboy Cologne     None\n"
     ]
    }
   ],
   "source": [
    "def load_catalog_data(file_path=\"\",debug=False):\n",
    "    \"\"\"\n",
    "    Load Apple Numbers file with multiple sheets into Pandas DataFrames.\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path: path to the Numbers file\n",
    "    \n",
    "    Returns:\n",
    "    - tables: dictionary of DataFrames, one for each sheet/table in the Numbers file\n",
    "    \"\"\"\n",
    "    # Read the Numbers file\n",
    "    doc = Document(file_path)\n",
    "    sheets = doc.sheets\n",
    "    tables = {}\n",
    "\n",
    "    # Extract each sheet as a separate dataframe\n",
    "    for sheet in sheets:\n",
    "        for table in sheet.tables:\n",
    "            table_name = table.name.replace(\" \", \"_\")\n",
    "            data = table.rows(values_only=True)\n",
    "            tables[table_name] = pd.DataFrame(data[1:], columns=data[0])\n",
    "\n",
    "    # Access individual dataframes\n",
    "    if debug:\n",
    "        for name, df in tables.items():\n",
    "            print(f\"\\n{name}:\")\n",
    "            print(df.head())\n",
    "\n",
    "    # For Product Catalog sheet replace spaces with underscores in column names\n",
    "    tables['Product_Catalog'].columns = tables['Product_Catalog'].columns.str.replace(' ', '_')\n",
    "    \n",
    "    return tables\n",
    "\n",
    "# Load the data\n",
    "file_path = \"CHARTS/catalog.numbers\"\n",
    "tables = load_catalog_data(file_path,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c526a54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet names and catalog features MATCH exactly!\n",
      "     Sheet_Names Catalog_Features\n",
      "0  Main_Category    Main_Category\n",
      "1   Sub_Category     Sub_Category\n",
      "2           Size             Size\n",
      "3            Fit              Fit\n",
      "4          Color            Color\n",
      "5         Design           Design\n",
      "6       Material         Material\n",
      "7          Scent            Scent\n"
     ]
    }
   ],
   "source": [
    "def validate_catalog_features(data=\"\",debug=False):\n",
    "    \"\"\"\n",
    "    Validate that code sheet names match catalog features and extract the feature list.\n",
    "    \n",
    "    Parameters:\n",
    "    - tables: dictionary of DataFrames from load_catalog_data()\n",
    "    \n",
    "    Returns:\n",
    "    - tuple: (code_sheet_list, catalog_feature_list)\n",
    "    \n",
    "    Raises:\n",
    "    - AssertionError if sheet names don't match catalog features\n",
    "    \"\"\"\n",
    "    # get lists of code sheets and catalog features\n",
    "    code_sheet_list = list(tables.keys())[2:]  # List of sheet names\n",
    "    catalog_feature_list = list(tables['Product_Catalog'].columns[1:])  # list of features from Product Catalog sheet excluding first column\n",
    "\n",
    "    # remove \"Name\" from catalog_feature_list if present\n",
    "    if \"Name\" in catalog_feature_list:\n",
    "        catalog_feature_list.remove(\"Name\")\n",
    "\n",
    "    # sanity check: make sure both lists match exactly\n",
    "    if set(code_sheet_list) == set(catalog_feature_list):\n",
    "        print(\"Sheet names and catalog features MATCH exactly!\")\n",
    "    else:\n",
    "        raise AssertionError(\"Sheet names and catalog features DO NOT match!\")\n",
    "\n",
    "    # for visual reference, create a DF to show matching sheets and features\n",
    "    matching_df = pd.DataFrame({\n",
    "        'Sheet_Names': code_sheet_list,\n",
    "        'Catalog_Features': catalog_feature_list\n",
    "    })\n",
    "    if debug:\n",
    "        print(matching_df)\n",
    "    \n",
    "    return code_sheet_list, catalog_feature_list\n",
    "\n",
    "# Validate and extract feature lists\n",
    "code_sheet_list, catalog_feature_list = validate_catalog_features(tables,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea560f8d",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1eb8435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All product names are unique, total batches to process: 18\n"
     ]
    }
   ],
   "source": [
    "# create a list of batch names from the set of unique Name field values in the product catalog\n",
    "\n",
    "def prepare_batches(data):\n",
    "    \"\"\"\n",
    "    Get unique product names from the Product Catalog and check for duplicates.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: DataFrame (Product_Catalog)\n",
    "    \n",
    "    Returns:\n",
    "    - list of unique product names (batch names)\n",
    "    \"\"\"\n",
    "    # Get unique names from the Name column\n",
    "    name_field_list = data['Name'].tolist()\n",
    "    name_field_set = set(name_field_list)\n",
    "    \n",
    "    # Check for duplicates by comparing list length to set length\n",
    "    has_duplicates = len(name_field_list) != len(name_field_set)\n",
    "    \n",
    "    if has_duplicates:\n",
    "        duplicate_list = []\n",
    "        print(f\"WARNING: Found {len(name_field_list) - len(name_field_set)} duplicate name(s)\")\n",
    "        # Find and print duplicates\n",
    "        seen = {}\n",
    "        for idx, name in enumerate(name_field_list):\n",
    "            if name in seen:\n",
    "                duplicate_list.append((name, seen[name], idx))\n",
    "            else:\n",
    "                seen[name] = idx\n",
    "        \n",
    "        # Print the duplicates\n",
    "        print(\"\\nDuplicate Names Found:\")\n",
    "        for name, first_idx, second_idx in duplicate_list:\n",
    "            print(f\"  '{name}' at indexes {first_idx} and {second_idx}\")\n",
    "    else:\n",
    "        print(f\"All product names are unique, total batches to process: {len(name_field_list)}\")\n",
    "    \n",
    "    return list(name_field_set)\n",
    "\n",
    "batch_name_list = prepare_batches(tables['Product_Catalog'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7f2d0a",
   "metadata": {},
   "source": [
    "### Permutation logic\n",
    "Generate dictionaries all possible permutations of a given prodcut model, extracting the feature, prefix, and index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product: Bandit Truck Logo Tee\n",
      "Number of permutations: 8\n",
      "\n",
      "Data imput type <class 'pandas.core.series.Series'>\n",
      "Data output type: <class 'list'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import re\n",
    "\n",
    "def generate_permutations(batch_name=\"\",debug=False):\n",
    "    \"\"\"\n",
    "    For a given product model (ie batch_name), generate all possible permutations of feature combinations.\n",
    "    Returns a list of dictionaries, where each dictionary represents one permutation.\n",
    "    Each value in the dict is [value_name, prefix, index] (as strings).\n",
    "    Prefix and index are from the corresponding code sheet.\n",
    "    For AND cases (semicolon), indexes are concatenated and value names are simplified.\n",
    "    Features with index '0' or prefix ending in 'NAN' are excluded (not applicable values).\n",
    "\n",
    "    Parameters:\n",
    "    - batch_name: String representing a row from Product_Catalog DataFrame\n",
    "    - debug: Boolean flag to enable debug printing\n",
    "    \n",
    "    Returns:\n",
    "    - List of dictionaries, each representing a permutation\n",
    "    \"\"\"\n",
    "\n",
    "    # Size abbreviation to full name mapping\n",
    "    size_mapping = {\n",
    "        'CS': 'Child Small',\n",
    "        'CM': 'Child Medium',\n",
    "        'CL': 'Child Large',\n",
    "        'XS': 'Extra Small',\n",
    "        'S': 'Small',\n",
    "        'M': 'Medium',\n",
    "        'L': 'Large',\n",
    "        'XL': 'Extra Large',\n",
    "        '2XL': 'Double Extra Large',\n",
    "        '3XL': 'Triple Extra Large',\n",
    "        '4XL': 'Quadruple Extra Large',\n",
    "        '5XL': 'Quintuple Extra Large',\n",
    "        'S/M': 'Small to Medium',\n",
    "        'L/XL': 'Large to Extra Large',\n",
    "        'NA': 'Not Applicable'\n",
    "    }\n",
    "    \n",
    "    # Dictionary to hold all feature values for this product model\n",
    "    feature_options = {}\n",
    "    \n",
    "    for feature in catalog_feature_list:\n",
    "        feature_values = batch_name[feature]\n",
    "        \n",
    "        # Check if feature_values contains comma or semicolon (is a list)\n",
    "        if isinstance(feature_values, str):\n",
    "            if ',' in feature_values:\n",
    "                # Comma-separated = \"OR\" - these create separate permutations\n",
    "                values = [v.strip() for v in feature_values.split(',')]\n",
    "                \n",
    "                # If this is Size feature, map abbreviations to full names\n",
    "                if feature == 'Size':\n",
    "                    values = [size_mapping.get(v, v) for v in values]\n",
    "                \n",
    "                feature_options[feature] = {\n",
    "                    'values': values,\n",
    "                    'type': 'OR'\n",
    "                }\n",
    "            elif ';' in feature_values:\n",
    "                # Semicolon-separated = \"AND\" - these must all appear together\n",
    "                values = [v.strip() for v in feature_values.split(';')]\n",
    "                \n",
    "                # If this is Size feature, map abbreviations to full names\n",
    "                if feature == 'Size':\n",
    "                    values = [size_mapping.get(v, v) for v in values]\n",
    "                \n",
    "                feature_options[feature] = {\n",
    "                    'values': values,\n",
    "                    'type': 'AND'\n",
    "                }\n",
    "            else:\n",
    "                # Single value\n",
    "                value = feature_values\n",
    "                \n",
    "                # If this is Size feature, map abbreviation to full name\n",
    "                if feature == 'Size':\n",
    "                    value = size_mapping.get(value.strip(), value)\n",
    "                \n",
    "                feature_options[feature] = {\n",
    "                    'values': [value],\n",
    "                    'type': 'SINGLE'\n",
    "                }\n",
    "        else:\n",
    "            # Non-string value (e.g., NaN, number) - treat as single value\n",
    "            feature_options[feature] = {\n",
    "                'values': [feature_values] if not pd.isna(feature_values) else [''],\n",
    "                'type': 'SINGLE'\n",
    "            }\n",
    "    \n",
    "    # Helper function to get prefix and index for a feature value\n",
    "    def get_value_info(feature, value_name):\n",
    "        \"\"\"Returns [value_name, prefix, index] for a given feature value.\"\"\"\n",
    "        code_sheet = tables[feature]\n",
    "        matching_rows = code_sheet.loc[code_sheet[\"Name\"] == value_name]\n",
    "        \n",
    "        if not matching_rows.empty:\n",
    "            code_index = matching_rows.index[0]\n",
    "            prefix = code_sheet.at[code_index, \"Prefix\"]\n",
    "            # Convert index to string (no padding)\n",
    "            index_str = str(code_index)\n",
    "            return [value_name, prefix, index_str]\n",
    "        else:\n",
    "            # If not found, return empty prefix and empty index\n",
    "            return [value_name, \"\", \"\"]\n",
    "    \n",
    "    # Helper function to check if a feature should be excluded\n",
    "    def is_not_applicable(value_info):\n",
    "        \"\"\"Returns True if the feature is 'Not Applicable' (index 0 or prefix ends with NAN)\"\"\"\n",
    "        index = value_info[2]\n",
    "        prefix = value_info[1]\n",
    "        return index == '0' or prefix.endswith('NAN')\n",
    "    \n",
    "    # Helper function to simplify value names for AND cases\n",
    "    def simplify_and_values(value_names):\n",
    "        \"\"\"\n",
    "        Simplifies multiple value names by finding common parts.\n",
    "        E.g., ['Bandit Truck Icon', 'Bandit Truck Wordmark'] -> 'Bandit Truck Icon AND Wordmark'\n",
    "        \"\"\"\n",
    "        if len(value_names) == 1:\n",
    "            return value_names[0]\n",
    "        \n",
    "        # Find common prefix among all names\n",
    "        common_prefix = \"\"\n",
    "        min_len = min(len(name) for name in value_names)\n",
    "        \n",
    "        for i in range(min_len):\n",
    "            if all(name[i] == value_names[0][i] for name in value_names):\n",
    "                common_prefix += value_names[0][i]\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        # Clean up common prefix (remove trailing spaces/incomplete words)\n",
    "        common_prefix = common_prefix.rstrip()\n",
    "        \n",
    "        # Extract unique parts from each name\n",
    "        unique_parts = []\n",
    "        for name in value_names:\n",
    "            unique_part = name[len(common_prefix):].strip()\n",
    "            if unique_part:\n",
    "                unique_parts.append(unique_part)\n",
    "        \n",
    "        # Construct simplified name\n",
    "        if common_prefix and unique_parts:\n",
    "            return f\"{common_prefix} {' AND '.join(unique_parts)}\"\n",
    "        else:\n",
    "            return ' AND '.join(value_names)\n",
    "    \n",
    "    # Separate features by type\n",
    "    or_features = {k: v['values'] for k, v in feature_options.items() if v['type'] == 'OR'}\n",
    "    and_features = {k: v['values'] for k, v in feature_options.items() if v['type'] == 'AND'}\n",
    "    single_features = {k: v['values'] for k, v in feature_options.items() if v['type'] == 'SINGLE'}\n",
    "    \n",
    "    # Build permutation components\n",
    "    permutation_dict = {}\n",
    "    \n",
    "    # Add single features (these don't multiply permutations)\n",
    "    for feature, values in single_features.items():\n",
    "        permutation_dict[feature] = values\n",
    "    \n",
    "    # Add OR features (these DO multiply permutations)\n",
    "    for feature, values in or_features.items():\n",
    "        permutation_dict[feature] = values\n",
    "    \n",
    "    # Generate all permutations using cartesian product\n",
    "    feature_names = list(permutation_dict.keys())\n",
    "    feature_value_lists = [permutation_dict[f] for f in feature_names]\n",
    "    \n",
    "    permutations = []\n",
    "    for combo in product(*feature_value_lists):\n",
    "        perm = {}\n",
    "        \n",
    "        # For each feature in this combination, get [value, prefix, index]\n",
    "        for feature, value_name in zip(feature_names, combo):\n",
    "            value_info = get_value_info(feature, value_name)\n",
    "            \n",
    "            # Skip if this is a \"Not Applicable\" value\n",
    "            if not is_not_applicable(value_info):\n",
    "                perm[feature] = value_info\n",
    "        \n",
    "        # Add AND features (combine into single [simplified_name, prefix, concatenated_indexes])\n",
    "        for feature, values in and_features.items():\n",
    "            # Get info for all values\n",
    "            value_infos = [get_value_info(feature, val) for val in values]\n",
    "            \n",
    "            # Check if any of the AND values are \"Not Applicable\"\n",
    "            if any(is_not_applicable(info) for info in value_infos):\n",
    "                continue  # Skip this entire AND feature\n",
    "            \n",
    "            # Simplify the value name\n",
    "            simplified_name = simplify_and_values([info[0] for info in value_infos])\n",
    "            \n",
    "            # Use first prefix (assuming they're all the same)\n",
    "            prefix = value_infos[0][1] if value_infos else \"\"\n",
    "            \n",
    "            # Concatenate indexes (no padding)\n",
    "            concatenated_index = \"\".join([info[2] for info in value_infos])\n",
    "            \n",
    "            perm[feature] = [simplified_name, prefix, concatenated_index]\n",
    "        \n",
    "        # Add the product name\n",
    "        perm['Name'] = batch_name['Name']\n",
    "        \n",
    "        permutations.append(perm)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Product: {batch_name['Name']}\")\n",
    "        print(f\"Number of permutations: {len(permutations)}\\n\")\n",
    "        print(f\"Data imput type {type(batch_name)}\")\n",
    "        print(f\"Data output type: {type(permutations)}\\n\")\n",
    "    \n",
    "    return permutations\n",
    "\n",
    "# Test permutation generation with arbitrary row\n",
    "test_row = tables['Product_Catalog'].iloc[2]\n",
    "permutations = generate_permutations(test_row,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb95a22b",
   "metadata": {},
   "source": [
    "### SKU number generation\n",
    "Generate unique SKUs based on the feature prefixes and indices. Use a timestamp with millisecond accuracy as a contingincy in the case of duplicate SKUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8ad1cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sku generated for\n",
      " Product Model: Bandit Truck Logo Tee\n",
      " variant: MAUS1-FT1-CL2-MAT1-SZ5-D45\n",
      " SKU length: 26\n"
     ]
    }
   ],
   "source": [
    "# generate a unique sku based on prefixes and indexes\n",
    "from datetime import datetime\n",
    "from multiprocessing.util import debug\n",
    "import base36\n",
    "\n",
    "def generate_sku(dict, add_timestamp=False, debug=False):\n",
    "    \"\"\"\n",
    "    Generate a SKU from a permutation dictionary.\n",
    "    \n",
    "    Parameters:\n",
    "    - dict: permutation dictionary with feature info\n",
    "    - add_timestamp: if True, adds a compact timestamp suffix for guaranteed uniqueness\n",
    "\n",
    "    Returns:\n",
    "    - Tuple: model_name, sku\n",
    "    \"\"\"\n",
    "\n",
    "    model_name = dict['Name']\n",
    "    part_list = []\n",
    "    sku_prefix = \"\"\n",
    "\n",
    "    # Create sku prefix for main prefix, and sub prefix and index\n",
    "    sku_prefix += dict['Main_Category'][1]\n",
    "    sku_prefix += dict['Sub_Category'][1]\n",
    "    sku_prefix += dict['Sub_Category'][2]\n",
    "    part_list.append(sku_prefix)\n",
    "\n",
    "\n",
    "    # iterate the rest of the dict items\n",
    "    for i, key in enumerate(dict.keys()):\n",
    "        if i >= 2 and key != \"Name\":  # only the third and proceeding items, exclude \"Name\"\n",
    "            # print(f\"key: {key}, value: {dict[key]}\")\n",
    "            part = dict[key][1] + dict[key][2]\n",
    "            part_list.append(part)\n",
    "\n",
    "    # Base SKU\n",
    "    sku = \"-\".join(part_list)\n",
    "    \n",
    "    # Add timestamp suffix if requested\n",
    "    if add_timestamp:\n",
    "        now = datetime.now()\n",
    "        unix_ms = int(now.timestamp() * 1000)\n",
    "        compact_time = base36.dumps(unix_ms)[-6:].upper()\n",
    "        \n",
    "        sku = f\"{sku}-{compact_time}\"\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Sku generated for\\n Product Model: {model_name}\\n variant: {sku}\\n SKU length: {len(sku)}\")\n",
    "\n",
    "    return (model_name, sku)\n",
    "\n",
    "# test on an arbitrary permutation\n",
    "model, sku = generate_sku(permutations[0],False,True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b97c32",
   "metadata": {},
   "source": [
    "## SKU number persistance\n",
    "Generate and write generate SKUs to a csv file with other product details. \n",
    "Prevent duplicate skus by checking the existing CSV and regenerate skus with timestamp based unique identifiers in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66037d3",
   "metadata": {},
   "source": [
    "#### Initialize an output CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92f0bfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: Attempting to create file at: Results/Bandit Truck Logo Tee_skus_20251121.csv\n",
      "Debug: Directory exists: True\n",
      "Debug: File exists: True\n",
      "Debug: Overwrite mode: True\n",
      "Overwriting existing CSV at: Results/Bandit Truck Logo Tee_skus_20251121.csv\n",
      "Created new CSV template with columns: ['Index', 'SKU', 'Main_Category', 'Sub_Category', 'Name', 'Size', 'Fit', 'Color', 'Design', 'Material', 'Scent']\n",
      "Saved to: Results/Bandit Truck Logo Tee_skus_20251121.csv\n",
      "\n",
      "Returned: Results/Bandit Truck Logo Tee_skus_20251121.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def initialize_output_csv(output_dir='', batch_name='', overwrite=False, debug=False):\n",
    "    \"\"\"\n",
    "    Initialize a CSV file for SKU batch output using a predefined template structure.\n",
    "    \n",
    "    Creates a timestamped CSV file with columns matching the sku_batch_template.csv format.\n",
    "    The filename includes the batch name and date for organization and tracking.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    output_dir : str\n",
    "        Directory path where the CSV should be created (e.g., 'Results/').\n",
    "        Directory will be created if it doesn't exist.\n",
    "    batch_name : str\n",
    "        Name of the product model/batch being processed. Used in the filename\n",
    "        for identification (e.g., 'Basic Tee' -> 'Basic Tee_skus_20251121.csv').\n",
    "    overwrite : bool, optional\n",
    "        Controls behavior when file already exists:\n",
    "        - False (default): Skips file creation and returns None\n",
    "        - True: Replaces existing file with new empty template\n",
    "    debug : bool, optional\n",
    "        If True, prints detailed diagnostic information including file paths,\n",
    "        directory status, and overwrite mode. Default is False.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str or None\n",
    "        Absolute path to the created CSV file if successful, or None if file\n",
    "        already exists and overwrite=False.\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    - File naming format: '{batch_name}_skus_{YYYYMMDD}.csv'\n",
    "    - Date-based naming allows multiple generations per batch on different days\n",
    "    - Template loaded from 'CHARTS/sku_batch_template.csv'\n",
    "    - All SKU columns from template are preserved in the output file\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    Create new batch file:\n",
    "    >>> path = initialize_output_csv('Results/', 'Basic Tee', overwrite=False)\n",
    "    >>> print(path)\n",
    "    'Results/Basic Tee_skus_20251121.csv'\n",
    "    \n",
    "    Overwrite existing batch file:\n",
    "    >>> path = initialize_output_csv('Results/', 'Basic Tee', overwrite=True)\n",
    "    Overwriting existing CSV at: Results/Basic Tee_skus_20251121.csv\n",
    "    \n",
    "    Debug mode for troubleshooting:\n",
    "    >>> path = initialize_output_csv('Results/', 'Basic Tee', debug=True)\n",
    "    Debug: Attempting to create file at: Results/Basic Tee_skus_20251121.csv\n",
    "    Debug: Directory exists: True\n",
    "    Debug: File exists: False\n",
    "    Debug: Overwrite mode: False\n",
    "    \"\"\"\n",
    "\n",
    "    # timestamp the file creation in the filepath\n",
    "    timestamp = datetime.now().strftime('%Y%m%d')\n",
    "\n",
    "    file_path = output_dir + batch_name + '_skus_' + timestamp + '.csv'\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Debug: Attempting to create file at: {file_path}\")\n",
    "        print(f\"Debug: Directory exists: {os.path.exists(output_dir)}\")\n",
    "        print(f\"Debug: File exists: {os.path.exists(file_path)}\")\n",
    "        print(f\"Debug: Overwrite mode: {overwrite}\")\n",
    "\n",
    "    # Check if FILE already exists (not directory)\n",
    "    if os.path.exists(file_path):\n",
    "        if not overwrite:\n",
    "            print(f\"CSV already exists at: {file_path}\")\n",
    "            print(f\"Set overwrite=True to replace existing file\")\n",
    "            return None\n",
    "        else:\n",
    "            print(f\"Overwriting existing CSV at: {file_path}\")\n",
    "    \n",
    "    # Load the template CSV from CHARTS directory\n",
    "    template_path = 'CHARTS/sku_batch_template.csv'\n",
    "    template_df = pd.read_csv(template_path)\n",
    "    template_columns = template_df.columns.tolist()\n",
    "    \n",
    "    # Create an empty DataFrame with these columns\n",
    "    output_df = pd.DataFrame(columns=template_columns)\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_df.to_csv(file_path, index=False)\n",
    "    \n",
    "    print(f\"Created new CSV template with columns: {template_columns}\")\n",
    "    print(f\"Saved to: {file_path}\")\n",
    "    \n",
    "    return file_path\n",
    "\n",
    "# Test the function\n",
    "output_dir = 'Results/'\n",
    "result = initialize_output_csv(output_dir, model, overwrite=True, debug=True)\n",
    "print(f\"\\nReturned: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335985a7",
   "metadata": {},
   "source": [
    "#### Parse batches into dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f3a1c5",
   "metadata": {},
   "source": [
    "### Sequential Permutation and Procedural SKU Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3635aa31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 'Legendary Polo': Generated 16 SKUs\n",
      "Batch 'Bandit Truck Wreath Sweater': Generated 8 SKUs\n",
      "Batch 'Legendary Trucker Hat': Generated 2 SKUs\n",
      "Batch 'Bandit Truck Trucker Hat': Generated 1 SKUs\n",
      "Batch 'Bandit Truck Flex Fit Hat': Generated 2 SKUs\n",
      "Batch 'Bandit Truck Jacket': Generated 8 SKUs\n",
      "Batch 'Bandit Banquet Tee': Generated 8 SKUs\n",
      "Batch 'Bandit Truck Wreath Tee': Generated 8 SKUs\n",
      "Batch 'Collectible Gold Keychain': Generated 2 SKUs\n",
      "Batch 'Legendary Hoody': Generated 8 SKUs\n",
      "Batch 'Legendary Long Sleeve Tee': Generated 8 SKUs\n",
      "Batch 'Legendary Tee': Generated 32 SKUs\n",
      "Batch 'Legendary Flex Fit Hat': Generated 2 SKUs\n",
      "Batch 'Legendary Jacket': Generated 8 SKUs\n",
      "Batch 'Legendary Sweater': Generated 8 SKUs\n",
      "Batch 'Bandit Truck Logo Tee': Generated 8 SKUs\n",
      "Batch 'Leather Air Freshener': Generated 6 SKUs\n",
      "Batch 'Legendary Distressed Hat': Generated 2 SKUs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_batch_dict(data=list,debug=False):\n",
    "    \"\"\"\n",
    "    Generate a dictionary capturing all generated SKU permutations for each batch.\n",
    "    Parameters:\n",
    "    - data: list of batch names (product models)\n",
    "    - debug: boolean flag to enable debug printing\n",
    "    Returns:\n",
    "    - batch_dict: dictionary where keys are batch names and values are lists of permutation dictionaries\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_dict = {} #capture updated batch data with SKUs\n",
    "\n",
    "    for batch_name in data:\n",
    "        # Get the row from Product_Catalog that matches this batch_name\n",
    "        batch_row = tables['Product_Catalog'][tables['Product_Catalog']['Name'] == batch_name].iloc[0]\n",
    "        \n",
    "        # Generate permutations for this batch (returns list of dictionaries)\n",
    "        permed_batch = generate_permutations(batch_row)\n",
    "        batch_dict[batch_name] = permed_batch\n",
    "        \n",
    "        # Add SKU to each permutation dictionary\n",
    "        for perm in permed_batch:\n",
    "            model, sku = generate_sku(perm)\n",
    "            perm['SKU'] = sku  # Add SKU key directly to the permutation dictionary\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"Batch '{batch_name}': Generated {len(permed_batch)} SKUs\")\n",
    "\n",
    "    return batch_dict\n",
    "\n",
    "batch_dict = generate_batch_dict(batch_name_list,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05086e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_to_dataframe(batch_name='',data_source=dict, batch_name_list=batch_name_list,debug=False):\n",
    "    \"\"\"\n",
    "    Convert a batch's list of permutation dictionaries to a Pandas DataFrame.\n",
    "    Parameters:\n",
    "    - batch_name: String name of the batch to convert\n",
    "    - data_source: Dictionary of batches\n",
    "    - batch_name_list: List of valid batch names (default: batch_name_list)\n",
    "    - debug: Boolean flag to enable debug printing\n",
    "    Returns:\n",
    "    - batch_df: Pandas DataFrame for the specified batch\n",
    "    \"\"\"\n",
    "    for batch in data_source:\n",
    "        if batch == batch_name:\n",
    "            batch_df = pd.DataFrame(data_source[batch])\n",
    "            batch_df.name = f\"{batch_name}_df\"\n",
    "            if debug:\n",
    "                print(f\"Converted batch '{batch_name}' to DataFrame\\n name: {batch_name}_df\\n Shape: {batch_df.shape}\")\n",
    "    return batch_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe273363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted batch 'Legendary Polo' to DataFrame\n",
      " name: Legendary Polo_df\n",
      " Shape: (16, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Main_Category</th>\n",
       "      <th>Sub_Category</th>\n",
       "      <th>Color</th>\n",
       "      <th>Material</th>\n",
       "      <th>Size</th>\n",
       "      <th>Fit</th>\n",
       "      <th>Design</th>\n",
       "      <th>Name</th>\n",
       "      <th>SKU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Shirt, MA, 1]</td>\n",
       "      <td>[Polo, US, 3]</td>\n",
       "      <td>[Black, CL, 2]</td>\n",
       "      <td>[Nylon, MAT, 2]</td>\n",
       "      <td>[Small, SZ, 5]</td>\n",
       "      <td>[Male, FT, 2]</td>\n",
       "      <td>[Legendary Icon AND Legendary Wordmark AND Ban...</td>\n",
       "      <td>Legendary Polo</td>\n",
       "      <td>MAUS3-CL2-MAT2-SZ5-FT2-D235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Shirt, MA, 1]</td>\n",
       "      <td>[Polo, US, 3]</td>\n",
       "      <td>[Black, CL, 2]</td>\n",
       "      <td>[Nylon, MAT, 2]</td>\n",
       "      <td>[Small, SZ, 5]</td>\n",
       "      <td>[Female, FT, 3]</td>\n",
       "      <td>[Legendary Icon AND Legendary Wordmark AND Ban...</td>\n",
       "      <td>Legendary Polo</td>\n",
       "      <td>MAUS3-CL2-MAT2-SZ5-FT3-D235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Shirt, MA, 1]</td>\n",
       "      <td>[Polo, US, 3]</td>\n",
       "      <td>[Black, CL, 2]</td>\n",
       "      <td>[Nylon, MAT, 2]</td>\n",
       "      <td>[Medium, SZ, 6]</td>\n",
       "      <td>[Male, FT, 2]</td>\n",
       "      <td>[Legendary Icon AND Legendary Wordmark AND Ban...</td>\n",
       "      <td>Legendary Polo</td>\n",
       "      <td>MAUS3-CL2-MAT2-SZ6-FT2-D235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Shirt, MA, 1]</td>\n",
       "      <td>[Polo, US, 3]</td>\n",
       "      <td>[Black, CL, 2]</td>\n",
       "      <td>[Nylon, MAT, 2]</td>\n",
       "      <td>[Medium, SZ, 6]</td>\n",
       "      <td>[Female, FT, 3]</td>\n",
       "      <td>[Legendary Icon AND Legendary Wordmark AND Ban...</td>\n",
       "      <td>Legendary Polo</td>\n",
       "      <td>MAUS3-CL2-MAT2-SZ6-FT3-D235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Shirt, MA, 1]</td>\n",
       "      <td>[Polo, US, 3]</td>\n",
       "      <td>[Black, CL, 2]</td>\n",
       "      <td>[Nylon, MAT, 2]</td>\n",
       "      <td>[Large, SZ, 7]</td>\n",
       "      <td>[Male, FT, 2]</td>\n",
       "      <td>[Legendary Icon AND Legendary Wordmark AND Ban...</td>\n",
       "      <td>Legendary Polo</td>\n",
       "      <td>MAUS3-CL2-MAT2-SZ7-FT2-D235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Shirt, MA, 1]</td>\n",
       "      <td>[Polo, US, 3]</td>\n",
       "      <td>[Black, CL, 2]</td>\n",
       "      <td>[Nylon, MAT, 2]</td>\n",
       "      <td>[Large, SZ, 7]</td>\n",
       "      <td>[Female, FT, 3]</td>\n",
       "      <td>[Legendary Icon AND Legendary Wordmark AND Ban...</td>\n",
       "      <td>Legendary Polo</td>\n",
       "      <td>MAUS3-CL2-MAT2-SZ7-FT3-D235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Shirt, MA, 1]</td>\n",
       "      <td>[Polo, US, 3]</td>\n",
       "      <td>[Black, CL, 2]</td>\n",
       "      <td>[Nylon, MAT, 2]</td>\n",
       "      <td>[Extra Large, SZ, 8]</td>\n",
       "      <td>[Male, FT, 2]</td>\n",
       "      <td>[Legendary Icon AND Legendary Wordmark AND Ban...</td>\n",
       "      <td>Legendary Polo</td>\n",
       "      <td>MAUS3-CL2-MAT2-SZ8-FT2-D235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Shirt, MA, 1]</td>\n",
       "      <td>[Polo, US, 3]</td>\n",
       "      <td>[Black, CL, 2]</td>\n",
       "      <td>[Nylon, MAT, 2]</td>\n",
       "      <td>[Extra Large, SZ, 8]</td>\n",
       "      <td>[Female, FT, 3]</td>\n",
       "      <td>[Legendary Icon AND Legendary Wordmark AND Ban...</td>\n",
       "      <td>Legendary Polo</td>\n",
       "      <td>MAUS3-CL2-MAT2-SZ8-FT3-D235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Shirt, MA, 1]</td>\n",
       "      <td>[Polo, US, 3]</td>\n",
       "      <td>[Black, CL, 2]</td>\n",
       "      <td>[Nylon, MAT, 2]</td>\n",
       "      <td>[Double Extra Large, SZ, 9]</td>\n",
       "      <td>[Male, FT, 2]</td>\n",
       "      <td>[Legendary Icon AND Legendary Wordmark AND Ban...</td>\n",
       "      <td>Legendary Polo</td>\n",
       "      <td>MAUS3-CL2-MAT2-SZ9-FT2-D235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Shirt, MA, 1]</td>\n",
       "      <td>[Polo, US, 3]</td>\n",
       "      <td>[Black, CL, 2]</td>\n",
       "      <td>[Nylon, MAT, 2]</td>\n",
       "      <td>[Double Extra Large, SZ, 9]</td>\n",
       "      <td>[Female, FT, 3]</td>\n",
       "      <td>[Legendary Icon AND Legendary Wordmark AND Ban...</td>\n",
       "      <td>Legendary Polo</td>\n",
       "      <td>MAUS3-CL2-MAT2-SZ9-FT3-D235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[Shirt, MA, 1]</td>\n",
       "      <td>[Polo, US, 3]</td>\n",
       "      <td>[Black, CL, 2]</td>\n",
       "      <td>[Nylon, MAT, 2]</td>\n",
       "      <td>[Triple Extra Large, SZ, 10]</td>\n",
       "      <td>[Male, FT, 2]</td>\n",
       "      <td>[Legendary Icon AND Legendary Wordmark AND Ban...</td>\n",
       "      <td>Legendary Polo</td>\n",
       "      <td>MAUS3-CL2-MAT2-SZ10-FT2-D235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[Shirt, MA, 1]</td>\n",
       "      <td>[Polo, US, 3]</td>\n",
       "      <td>[Black, CL, 2]</td>\n",
       "      <td>[Nylon, MAT, 2]</td>\n",
       "      <td>[Triple Extra Large, SZ, 10]</td>\n",
       "      <td>[Female, FT, 3]</td>\n",
       "      <td>[Legendary Icon AND Legendary Wordmark AND Ban...</td>\n",
       "      <td>Legendary Polo</td>\n",
       "      <td>MAUS3-CL2-MAT2-SZ10-FT3-D235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[Shirt, MA, 1]</td>\n",
       "      <td>[Polo, US, 3]</td>\n",
       "      <td>[Black, CL, 2]</td>\n",
       "      <td>[Nylon, MAT, 2]</td>\n",
       "      <td>[Quadruple Extra Large, SZ, 11]</td>\n",
       "      <td>[Male, FT, 2]</td>\n",
       "      <td>[Legendary Icon AND Legendary Wordmark AND Ban...</td>\n",
       "      <td>Legendary Polo</td>\n",
       "      <td>MAUS3-CL2-MAT2-SZ11-FT2-D235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[Shirt, MA, 1]</td>\n",
       "      <td>[Polo, US, 3]</td>\n",
       "      <td>[Black, CL, 2]</td>\n",
       "      <td>[Nylon, MAT, 2]</td>\n",
       "      <td>[Quadruple Extra Large, SZ, 11]</td>\n",
       "      <td>[Female, FT, 3]</td>\n",
       "      <td>[Legendary Icon AND Legendary Wordmark AND Ban...</td>\n",
       "      <td>Legendary Polo</td>\n",
       "      <td>MAUS3-CL2-MAT2-SZ11-FT3-D235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[Shirt, MA, 1]</td>\n",
       "      <td>[Polo, US, 3]</td>\n",
       "      <td>[Black, CL, 2]</td>\n",
       "      <td>[Nylon, MAT, 2]</td>\n",
       "      <td>[Quintuple Extra Large, SZ, 12]</td>\n",
       "      <td>[Male, FT, 2]</td>\n",
       "      <td>[Legendary Icon AND Legendary Wordmark AND Ban...</td>\n",
       "      <td>Legendary Polo</td>\n",
       "      <td>MAUS3-CL2-MAT2-SZ12-FT2-D235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[Shirt, MA, 1]</td>\n",
       "      <td>[Polo, US, 3]</td>\n",
       "      <td>[Black, CL, 2]</td>\n",
       "      <td>[Nylon, MAT, 2]</td>\n",
       "      <td>[Quintuple Extra Large, SZ, 12]</td>\n",
       "      <td>[Female, FT, 3]</td>\n",
       "      <td>[Legendary Icon AND Legendary Wordmark AND Ban...</td>\n",
       "      <td>Legendary Polo</td>\n",
       "      <td>MAUS3-CL2-MAT2-SZ12-FT3-D235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Main_Category   Sub_Category           Color         Material  \\\n",
       "0   [Shirt, MA, 1]  [Polo, US, 3]  [Black, CL, 2]  [Nylon, MAT, 2]   \n",
       "1   [Shirt, MA, 1]  [Polo, US, 3]  [Black, CL, 2]  [Nylon, MAT, 2]   \n",
       "2   [Shirt, MA, 1]  [Polo, US, 3]  [Black, CL, 2]  [Nylon, MAT, 2]   \n",
       "3   [Shirt, MA, 1]  [Polo, US, 3]  [Black, CL, 2]  [Nylon, MAT, 2]   \n",
       "4   [Shirt, MA, 1]  [Polo, US, 3]  [Black, CL, 2]  [Nylon, MAT, 2]   \n",
       "5   [Shirt, MA, 1]  [Polo, US, 3]  [Black, CL, 2]  [Nylon, MAT, 2]   \n",
       "6   [Shirt, MA, 1]  [Polo, US, 3]  [Black, CL, 2]  [Nylon, MAT, 2]   \n",
       "7   [Shirt, MA, 1]  [Polo, US, 3]  [Black, CL, 2]  [Nylon, MAT, 2]   \n",
       "8   [Shirt, MA, 1]  [Polo, US, 3]  [Black, CL, 2]  [Nylon, MAT, 2]   \n",
       "9   [Shirt, MA, 1]  [Polo, US, 3]  [Black, CL, 2]  [Nylon, MAT, 2]   \n",
       "10  [Shirt, MA, 1]  [Polo, US, 3]  [Black, CL, 2]  [Nylon, MAT, 2]   \n",
       "11  [Shirt, MA, 1]  [Polo, US, 3]  [Black, CL, 2]  [Nylon, MAT, 2]   \n",
       "12  [Shirt, MA, 1]  [Polo, US, 3]  [Black, CL, 2]  [Nylon, MAT, 2]   \n",
       "13  [Shirt, MA, 1]  [Polo, US, 3]  [Black, CL, 2]  [Nylon, MAT, 2]   \n",
       "14  [Shirt, MA, 1]  [Polo, US, 3]  [Black, CL, 2]  [Nylon, MAT, 2]   \n",
       "15  [Shirt, MA, 1]  [Polo, US, 3]  [Black, CL, 2]  [Nylon, MAT, 2]   \n",
       "\n",
       "                               Size              Fit  \\\n",
       "0                    [Small, SZ, 5]    [Male, FT, 2]   \n",
       "1                    [Small, SZ, 5]  [Female, FT, 3]   \n",
       "2                   [Medium, SZ, 6]    [Male, FT, 2]   \n",
       "3                   [Medium, SZ, 6]  [Female, FT, 3]   \n",
       "4                    [Large, SZ, 7]    [Male, FT, 2]   \n",
       "5                    [Large, SZ, 7]  [Female, FT, 3]   \n",
       "6              [Extra Large, SZ, 8]    [Male, FT, 2]   \n",
       "7              [Extra Large, SZ, 8]  [Female, FT, 3]   \n",
       "8       [Double Extra Large, SZ, 9]    [Male, FT, 2]   \n",
       "9       [Double Extra Large, SZ, 9]  [Female, FT, 3]   \n",
       "10     [Triple Extra Large, SZ, 10]    [Male, FT, 2]   \n",
       "11     [Triple Extra Large, SZ, 10]  [Female, FT, 3]   \n",
       "12  [Quadruple Extra Large, SZ, 11]    [Male, FT, 2]   \n",
       "13  [Quadruple Extra Large, SZ, 11]  [Female, FT, 3]   \n",
       "14  [Quintuple Extra Large, SZ, 12]    [Male, FT, 2]   \n",
       "15  [Quintuple Extra Large, SZ, 12]  [Female, FT, 3]   \n",
       "\n",
       "                                               Design            Name  \\\n",
       "0   [Legendary Icon AND Legendary Wordmark AND Ban...  Legendary Polo   \n",
       "1   [Legendary Icon AND Legendary Wordmark AND Ban...  Legendary Polo   \n",
       "2   [Legendary Icon AND Legendary Wordmark AND Ban...  Legendary Polo   \n",
       "3   [Legendary Icon AND Legendary Wordmark AND Ban...  Legendary Polo   \n",
       "4   [Legendary Icon AND Legendary Wordmark AND Ban...  Legendary Polo   \n",
       "5   [Legendary Icon AND Legendary Wordmark AND Ban...  Legendary Polo   \n",
       "6   [Legendary Icon AND Legendary Wordmark AND Ban...  Legendary Polo   \n",
       "7   [Legendary Icon AND Legendary Wordmark AND Ban...  Legendary Polo   \n",
       "8   [Legendary Icon AND Legendary Wordmark AND Ban...  Legendary Polo   \n",
       "9   [Legendary Icon AND Legendary Wordmark AND Ban...  Legendary Polo   \n",
       "10  [Legendary Icon AND Legendary Wordmark AND Ban...  Legendary Polo   \n",
       "11  [Legendary Icon AND Legendary Wordmark AND Ban...  Legendary Polo   \n",
       "12  [Legendary Icon AND Legendary Wordmark AND Ban...  Legendary Polo   \n",
       "13  [Legendary Icon AND Legendary Wordmark AND Ban...  Legendary Polo   \n",
       "14  [Legendary Icon AND Legendary Wordmark AND Ban...  Legendary Polo   \n",
       "15  [Legendary Icon AND Legendary Wordmark AND Ban...  Legendary Polo   \n",
       "\n",
       "                             SKU  \n",
       "0    MAUS3-CL2-MAT2-SZ5-FT2-D235  \n",
       "1    MAUS3-CL2-MAT2-SZ5-FT3-D235  \n",
       "2    MAUS3-CL2-MAT2-SZ6-FT2-D235  \n",
       "3    MAUS3-CL2-MAT2-SZ6-FT3-D235  \n",
       "4    MAUS3-CL2-MAT2-SZ7-FT2-D235  \n",
       "5    MAUS3-CL2-MAT2-SZ7-FT3-D235  \n",
       "6    MAUS3-CL2-MAT2-SZ8-FT2-D235  \n",
       "7    MAUS3-CL2-MAT2-SZ8-FT3-D235  \n",
       "8    MAUS3-CL2-MAT2-SZ9-FT2-D235  \n",
       "9    MAUS3-CL2-MAT2-SZ9-FT3-D235  \n",
       "10  MAUS3-CL2-MAT2-SZ10-FT2-D235  \n",
       "11  MAUS3-CL2-MAT2-SZ10-FT3-D235  \n",
       "12  MAUS3-CL2-MAT2-SZ11-FT2-D235  \n",
       "13  MAUS3-CL2-MAT2-SZ11-FT3-D235  \n",
       "14  MAUS3-CL2-MAT2-SZ12-FT2-D235  \n",
       "15  MAUS3-CL2-MAT2-SZ12-FT3-D235  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "batch_name = batch_name_list[0]\n",
    "\n",
    "batch_to_dataframe(batch_name,batch_dict,debug=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecb7e6a",
   "metadata": {},
   "source": [
    "## SKU number capture test\n",
    "\n",
    "run the above functions to generate SKUs and write them into the initialized csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99869a93",
   "metadata": {},
   "source": [
    "### Prepare Data For Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "6725a1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet names and catalog features MATCH exactly!\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "tables = load_catalog_data(\"CHARTS/catalog.numbers\")\n",
    "\n",
    "# Validate and extract feature lists\n",
    "code_sheet_list, catalog_feature_list = validate_catalog_features(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04418dbf",
   "metadata": {},
   "source": [
    "### Write generated SKUS to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673174cc",
   "metadata": {},
   "source": [
    "Start with a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8db15d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
